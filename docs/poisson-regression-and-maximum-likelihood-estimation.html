<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lesson 10 Poisson Regression and Maximum Likelihood Estimation | Empirical Research Methods</title>
  <meta name="description" content="Lesson 10 Poisson Regression and Maximum Likelihood Estimation | Empirical Research Methods" />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Lesson 10 Poisson Regression and Maximum Likelihood Estimation | Empirical Research Methods" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lesson 10 Poisson Regression and Maximum Likelihood Estimation | Empirical Research Methods" />
  
  
  

<meta name="author" content="Francis J. DiTraglia" />


<meta name="date" content="2022-06-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-rodeo.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="include/webex.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="images/core-erm-logo.png"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i>About This Book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#pre-requisites"><i class="fa fa-check"></i>Pre-requisites</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#good-coding-style"><i class="fa fa-check"></i>Good Coding Style</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#r-markdown"><i class="fa fa-check"></i>R Markdown</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-not-stata"><i class="fa fa-check"></i>Why not Stata?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-not-matlab-julia-or-python"><i class="fa fa-check"></i>Why not Matlab, Julia, or Python?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#you-can-help-make-this-book-better"><i class="fa fa-check"></i>You can help make this book better!</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html"><i class="fa fa-check"></i><b>1</b> Getting Started with <code>dplyr</code></a>
<ul>
<li class="chapter" data-level="1.1" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#package-installation"><i class="fa fa-check"></i><b>1.1</b> Package Installation</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#exercise"><i class="fa fa-check"></i><b>1.1.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#what-is-a-tibble"><i class="fa fa-check"></i><b>1.2</b> What is a tibble?</a></li>
<li class="chapter" data-level="1.3" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#filter-rows-with-filter"><i class="fa fa-check"></i><b>1.3</b> Filter Rows with <code>filter</code></a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#exercises"><i class="fa fa-check"></i><b>1.3.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#sort-data-with-arrange"><i class="fa fa-check"></i><b>1.4</b> Sort data with <code>arrange</code></a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#exercises-1"><i class="fa fa-check"></i><b>1.4.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#choose-columns-with-select"><i class="fa fa-check"></i><b>1.5</b> Choose columns with <code>select</code></a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#exercise-1"><i class="fa fa-check"></i><b>1.5.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#the-summarize-verb"><i class="fa fa-check"></i><b>1.6</b> The <code>summarize</code> verb</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#exercise-2"><i class="fa fa-check"></i><b>1.6.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#the-group_by-verb"><i class="fa fa-check"></i><b>1.7</b> The <code>group_by</code> verb</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#exercise-3"><i class="fa fa-check"></i><b>1.7.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#understanding-the-pipe"><i class="fa fa-check"></i><b>1.8</b> Understanding the pipe: <code>%&gt;%</code></a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#exercise-4"><i class="fa fa-check"></i><b>1.8.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#chaining-commands"><i class="fa fa-check"></i><b>1.9</b> Chaining commands</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#exercise-5"><i class="fa fa-check"></i><b>1.9.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#change-an-existing-variable-or-create-a-new-one-with-mutate"><i class="fa fa-check"></i><b>1.10</b> Change an existing variable or create a new one with <code>mutate</code></a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="getting-started-with-dplyr.html"><a href="getting-started-with-dplyr.html#exercise-6"><i class="fa fa-check"></i><b>1.10.1</b> Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html"><i class="fa fa-check"></i><b>2</b> Getting Started with <code>ggplot2</code></a>
<ul>
<li class="chapter" data-level="2.1" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#a-simple-scatterplot-using-ggplot2"><i class="fa fa-check"></i><b>2.1</b> A simple scatterplot using <code>ggplot2</code></a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#exercise-7"><i class="fa fa-check"></i><b>2.1.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#plotting-on-the-log-scale"><i class="fa fa-check"></i><b>2.2</b> Plotting on the log scale</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#exercise-8"><i class="fa fa-check"></i><b>2.2.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#the-color-and-size-aesthetics"><i class="fa fa-check"></i><b>2.3</b> The color and size aesthetics</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#exercise-9"><i class="fa fa-check"></i><b>2.3.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#faceting---plots-for-multiple-subsets"><i class="fa fa-check"></i><b>2.4</b> Faceting - Plots for Multiple Subsets</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#exercise-10"><i class="fa fa-check"></i><b>2.4.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#plotting-summarized-data"><i class="fa fa-check"></i><b>2.5</b> Plotting summarized data</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#exercise-11"><i class="fa fa-check"></i><b>2.5.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#line-plots"><i class="fa fa-check"></i><b>2.6</b> Line plots</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#exercise-12"><i class="fa fa-check"></i><b>2.6.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#bar-plots"><i class="fa fa-check"></i><b>2.7</b> Bar plots</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#exercise-13"><i class="fa fa-check"></i><b>2.7.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#cleveland-dot-charts"><i class="fa fa-check"></i><b>2.8</b> Cleveland Dot Charts</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#exercise-14"><i class="fa fa-check"></i><b>2.8.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#histograms"><i class="fa fa-check"></i><b>2.9</b> Histograms</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#exercise-15"><i class="fa fa-check"></i><b>2.9.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#boxplots"><i class="fa fa-check"></i><b>2.10</b> Boxplots</a>
<ul>
<li class="chapter" data-level="2.10.1" data-path="getting-started-with-ggplot2.html"><a href="getting-started-with-ggplot2.html#exercise-16"><i class="fa fa-check"></i><b>2.10.1</b> Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html"><i class="fa fa-check"></i><b>3</b> Predictive Regression Part I</a>
<ul>
<li class="chapter" data-level="3.1" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#exercise-17"><i class="fa fa-check"></i><b>3.1.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#the-least-squares-problem"><i class="fa fa-check"></i><b>3.2</b> The Least Squares Problem</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#exercise-18"><i class="fa fa-check"></i><b>3.2.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#linear-regression-with-lm"><i class="fa fa-check"></i><b>3.3</b> Linear Regression with <code>lm()</code></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#exercise-19"><i class="fa fa-check"></i><b>3.3.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#plotting-the-regression-line"><i class="fa fa-check"></i><b>3.4</b> Plotting the Regression Line</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#exercise-20"><i class="fa fa-check"></i><b>3.4.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#getting-more-from-lm"><i class="fa fa-check"></i><b>3.5</b> Getting More from <code>lm()</code></a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#exercise-21"><i class="fa fa-check"></i><b>3.5.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#summarizing-the-ouput-of-lm"><i class="fa fa-check"></i><b>3.6</b> Summarizing The Ouput of <code>lm()</code></a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#exercise-22"><i class="fa fa-check"></i><b>3.6.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#tidying-up-with-broom"><i class="fa fa-check"></i><b>3.7</b> Tidying up with <code>broom</code></a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#exercise-23"><i class="fa fa-check"></i><b>3.7.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#dummy-variables-with-lm"><i class="fa fa-check"></i><b>3.8</b> Dummy Variables with <code>lm()</code></a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#exercise-24"><i class="fa fa-check"></i><b>3.8.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#fun-with-r-formulas"><i class="fa fa-check"></i><b>3.9</b> Fun with R Formulas</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#everything-else---the-dot-."><i class="fa fa-check"></i><b>3.9.1</b> "Everything Else" - The Dot <code>.</code></a></li>
<li class="chapter" data-level="3.9.2" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#removing-predictors-with--"><i class="fa fa-check"></i><b>3.9.2</b> Removing Predictors with <code>-</code></a></li>
<li class="chapter" data-level="3.9.3" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#the-intercept-1"><i class="fa fa-check"></i><b>3.9.3</b> The Intercept: <code>1</code></a></li>
<li class="chapter" data-level="3.9.4" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#exercise-25"><i class="fa fa-check"></i><b>3.9.4</b> Exercise</a></li>
<li class="chapter" data-level="3.9.5" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#transforming-outcomes-and-predictors"><i class="fa fa-check"></i><b>3.9.5</b> Transforming Outcomes and Predictors</a></li>
<li class="chapter" data-level="3.9.6" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#adding-interactions-with-and"><i class="fa fa-check"></i><b>3.9.6</b> Adding Interactions With <code>:</code>, <code>*</code>, and <code>^</code></a></li>
<li class="chapter" data-level="3.9.7" data-path="predictive-regression-part-i.html"><a href="predictive-regression-part-i.html#exercise-26"><i class="fa fa-check"></i><b>3.9.7</b> Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html"><i class="fa fa-check"></i><b>4</b> Predictive Regression Part II</a>
<ul>
<li class="chapter" data-level="4.1" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#regressions-used-below"><i class="fa fa-check"></i><b>4.1</b> Regressions Used Below</a></li>
<li class="chapter" data-level="4.2" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#predicting-new-observations"><i class="fa fa-check"></i><b>4.2</b> Predicting New Observations</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#exercise-27"><i class="fa fa-check"></i><b>4.2.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#testing-a-linear-restriction"><i class="fa fa-check"></i><b>4.3</b> Testing a Linear Restriction</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#exercise-28"><i class="fa fa-check"></i><b>4.3.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#heteroskedasticity-robust-standard-errors-and-tests"><i class="fa fa-check"></i><b>4.4</b> Heteroskedasticity-Robust Standard Errors and Tests</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#exercise-29"><i class="fa fa-check"></i><b>4.4.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#publication-quality-tables"><i class="fa fa-check"></i><b>4.5</b> Publication Quality Tables</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#datasummary_skim"><i class="fa fa-check"></i><b>4.5.1</b> <code>datasummary_skim()</code></a></li>
<li class="chapter" data-level="4.5.2" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#datasummary_balance"><i class="fa fa-check"></i><b>4.5.2</b> <code>datasummary_balance()</code></a></li>
<li class="chapter" data-level="4.5.3" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#modelsummary"><i class="fa fa-check"></i><b>4.5.3</b> <code>modelsummary()</code></a></li>
<li class="chapter" data-level="4.5.4" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#robust-standard-errors"><i class="fa fa-check"></i><b>4.5.4</b> Robust Standard Errors</a></li>
<li class="chapter" data-level="4.5.5" data-path="predictive-regression-part-ii.html"><a href="predictive-regression-part-ii.html#exercise-30"><i class="fa fa-check"></i><b>4.5.5</b> Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html"><i class="fa fa-check"></i><b>5</b> Running a Simulation Study</a>
<ul>
<li class="chapter" data-level="5.1" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#is-the-hot-hand-an-illusion"><i class="fa fa-check"></i><b>5.1</b> Is the Hot Hand an Illusion?</a></li>
<li class="chapter" data-level="5.2" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#drawing-random-data-in-r"><i class="fa fa-check"></i><b>5.2</b> Drawing Random Data in R</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#sample"><i class="fa fa-check"></i><b>5.2.1</b> <code>sample()</code></a></li>
<li class="chapter" data-level="5.2.2" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#probability-distributions-in-r"><i class="fa fa-check"></i><b>5.2.2</b> Probability Distributions in R</a></li>
<li class="chapter" data-level="5.2.3" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#set.seed"><i class="fa fa-check"></i><b>5.2.3</b> <code>set.seed()</code></a></li>
<li class="chapter" data-level="5.2.4" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#exercises-2"><i class="fa fa-check"></i><b>5.2.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#the-skeleton-of-a-simulation-study"><i class="fa fa-check"></i><b>5.3</b> The Skeleton of a Simulation Study</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#a-biased-estimator-of-sigma2"><i class="fa fa-check"></i><b>5.3.1</b> A Biased Estimator of <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="5.3.2" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#draw_sim_data"><i class="fa fa-check"></i><b>5.3.2</b> <code>draw_sim_data()</code></a></li>
<li class="chapter" data-level="5.3.3" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#get_estimate"><i class="fa fa-check"></i><b>5.3.3</b> <code>get_estimate()</code></a></li>
<li class="chapter" data-level="5.3.4" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#get_bias"><i class="fa fa-check"></i><b>5.3.4</b> <code>get_bias()</code></a></li>
<li class="chapter" data-level="5.3.5" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#running-the-simulation-study"><i class="fa fa-check"></i><b>5.3.5</b> Running the Simulation Study</a></li>
<li class="chapter" data-level="5.3.6" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#expand.grid-and-map"><i class="fa fa-check"></i><b>5.3.6</b> <code>expand.grid()</code> and <code>Map()</code></a></li>
<li class="chapter" data-level="5.3.7" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#formatting-the-results"><i class="fa fa-check"></i><b>5.3.7</b> Formatting the Results</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="running-a-simulation-study.html"><a href="running-a-simulation-study.html#exercise---the-hot-hand"><i class="fa fa-check"></i><b>5.4</b> Exercise - The Hot Hand</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html"><i class="fa fa-check"></i><b>6</b> Logistic Regression and Friends</a>
<ul>
<li class="chapter" data-level="6.1" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#understanding-the-logistic-regression-model"><i class="fa fa-check"></i><b>6.1</b> Understanding the Logistic Regression Model</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#odds-arent-so-odd"><i class="fa fa-check"></i><b>6.1.1</b> Odds aren't so odd!</a></li>
<li class="chapter" data-level="6.1.2" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#exercise-31"><i class="fa fa-check"></i><b>6.1.2</b> Exercise</a></li>
<li class="chapter" data-level="6.1.3" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#interpreting-a-simple-logit-regression-model"><i class="fa fa-check"></i><b>6.1.3</b> Interpreting a Simple Logit Regression Model</a></li>
<li class="chapter" data-level="6.1.4" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#exercise-32"><i class="fa fa-check"></i><b>6.1.4</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#simulating-data-from-a-logistic-regression"><i class="fa fa-check"></i><b>6.2</b> Simulating Data from a Logistic Regression</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#exercise-33"><i class="fa fa-check"></i><b>6.2.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#running-a-logistic-regression-in-r"><i class="fa fa-check"></i><b>6.3</b> Running a Logistic Regression in R</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#exercise-34"><i class="fa fa-check"></i><b>6.3.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#predicted-probabilities-for-logistic-regression"><i class="fa fa-check"></i><b>6.4</b> Predicted Probabilities for Logistic Regression</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#exercise-35"><i class="fa fa-check"></i><b>6.4.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#plotting-a-logistic-regression"><i class="fa fa-check"></i><b>6.5</b> Plotting a Logistic Regression</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#exercise-36"><i class="fa fa-check"></i><b>6.5.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#probit-regression-and-the-linear-probability-model"><i class="fa fa-check"></i><b>6.6</b> Probit Regression and the Linear Probability Model</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#probit-regression"><i class="fa fa-check"></i><b>6.6.1</b> Probit Regression</a></li>
<li class="chapter" data-level="6.6.2" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#the-linear-probability-model"><i class="fa fa-check"></i><b>6.6.2</b> The Linear Probability Model</a></li>
<li class="chapter" data-level="6.6.3" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#exercise-37"><i class="fa fa-check"></i><b>6.6.3</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#addendum-odds-and-ends-about-risk"><i class="fa fa-check"></i><b>6.7</b> Addendum: Odds and Ends about Risk</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="logistic-regression-and-friends.html"><a href="logistic-regression-and-friends.html#exercise-38"><i class="fa fa-check"></i><b>6.7.1</b> Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html"><i class="fa fa-check"></i><b>7</b> The Normal Distribution</a>
<ul>
<li class="chapter" data-level="7.1" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#standard-normals-as-building-blocks"><i class="fa fa-check"></i><b>7.1</b> Standard Normals as Building Blocks</a></li>
<li class="chapter" data-level="7.2" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#the-one-dimensional-case"><i class="fa fa-check"></i><b>7.2</b> The One-Dimensional Case</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#pnorm"><i class="fa fa-check"></i><b>7.2.1</b> <code>pnorm()</code></a></li>
<li class="chapter" data-level="7.2.2" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#dnorm"><i class="fa fa-check"></i><b>7.2.2</b> <code>dnorm()</code></a></li>
<li class="chapter" data-level="7.2.3" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#qnorm"><i class="fa fa-check"></i><b>7.2.3</b> <code>qnorm()</code></a></li>
<li class="chapter" data-level="7.2.4" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#rnorm"><i class="fa fa-check"></i><b>7.2.4</b> <code>rnorm()</code></a></li>
<li class="chapter" data-level="7.2.5" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#pqdrnorm-are-vectorized"><i class="fa fa-check"></i><b>7.2.5</b> <code>p/q/d/rnorm()</code> are Vectorized</a></li>
<li class="chapter" data-level="7.2.6" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#be-careful"><i class="fa fa-check"></i><b>7.2.6</b> Be Careful!</a></li>
<li class="chapter" data-level="7.2.7" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#exercises-3"><i class="fa fa-check"></i><b>7.2.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#generating-correlated-normal-rvs"><i class="fa fa-check"></i><b>7.3</b> Generating Correlated Normal RVs</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#start-with-uncorrelated-normal-draws"><i class="fa fa-check"></i><b>7.3.1</b> Start with Uncorrelated Normal Draws</a></li>
<li class="chapter" data-level="7.3.2" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#exercise-39"><i class="fa fa-check"></i><b>7.3.2</b> Exercise</a></li>
<li class="chapter" data-level="7.3.3" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#add-constants-to-shift-the-means"><i class="fa fa-check"></i><b>7.3.3</b> Add Constants to Shift the Means</a></li>
<li class="chapter" data-level="7.3.4" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#exercise-40"><i class="fa fa-check"></i><b>7.3.4</b> Exercise</a></li>
<li class="chapter" data-level="7.3.5" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#multiply-by-scalars-to-change-the-variance"><i class="fa fa-check"></i><b>7.3.5</b> Multiply by Scalars to Change the Variance</a></li>
<li class="chapter" data-level="7.3.6" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#combine-to-create-correlation"><i class="fa fa-check"></i><b>7.3.6</b> Combine to Create Correlation</a></li>
<li class="chapter" data-level="7.3.7" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#exercise-41"><i class="fa fa-check"></i><b>7.3.7</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#the-cholesky-decomposition"><i class="fa fa-check"></i><b>7.4</b> The Cholesky Decomposition</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#going-backwards"><i class="fa fa-check"></i><b>7.4.1</b> Going Backwards</a></li>
<li class="chapter" data-level="7.4.2" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#exercise-42"><i class="fa fa-check"></i><b>7.4.2</b> Exercise</a></li>
<li class="chapter" data-level="7.4.3" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#whats-the-square-root-of-a-matrix"><i class="fa fa-check"></i><b>7.4.3</b> What's the Square Root of a Matrix?</a></li>
<li class="chapter" data-level="7.4.4" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#exercise-43"><i class="fa fa-check"></i><b>7.4.4</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#epilogue"><i class="fa fa-check"></i><b>7.5</b> Epilogue</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#affine-transformations-of-a-multivariate-normal"><i class="fa fa-check"></i><b>7.5.1</b> Affine Transformations of a Multivariate Normal</a></li>
<li class="chapter" data-level="7.5.2" data-path="the-normal-distribution.html"><a href="the-normal-distribution.html#conditional-distributions-of-bivariate-normal"><i class="fa fa-check"></i><b>7.5.2</b> Conditional Distributions of Bivariate Normal</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="text-data.html"><a href="text-data.html"><i class="fa fa-check"></i><b>8</b> Text Data</a>
<ul>
<li class="chapter" data-level="8.1" data-path="text-data.html"><a href="text-data.html#unnest_tokens"><i class="fa fa-check"></i><b>8.1</b> <code>unnest_tokens()</code></a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="text-data.html"><a href="text-data.html#exercise-44"><i class="fa fa-check"></i><b>8.1.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="text-data.html"><a href="text-data.html#stop_words-and-word-clouds"><i class="fa fa-check"></i><b>8.2</b> <code>stop_words</code> and Word Clouds</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="text-data.html"><a href="text-data.html#exercise-45"><i class="fa fa-check"></i><b>8.2.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="text-data.html"><a href="text-data.html#stemming-and-removing-numbers"><i class="fa fa-check"></i><b>8.3</b> Stemming and Removing Numbers</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="text-data.html"><a href="text-data.html#exercise-46"><i class="fa fa-check"></i><b>8.3.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="text-data.html"><a href="text-data.html#zipfs-law"><i class="fa fa-check"></i><b>8.4</b> Zipf's Law</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="text-data.html"><a href="text-data.html#exercise-47"><i class="fa fa-check"></i><b>8.4.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="text-data.html"><a href="text-data.html#bind_tf_idf"><i class="fa fa-check"></i><b>8.5</b> <code>bind_tf_idf()</code></a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="text-data.html"><a href="text-data.html#exercise-48"><i class="fa fa-check"></i><b>8.5.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="text-data.html"><a href="text-data.html#reading-a-corpus-into-r"><i class="fa fa-check"></i><b>8.6</b> Reading a Corpus into R</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="text-data.html"><a href="text-data.html#exercise-49"><i class="fa fa-check"></i><b>8.6.1</b> Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="data-rodeo.html"><a href="data-rodeo.html"><i class="fa fa-check"></i><b>9</b> Data Rodeo</a>
<ul>
<li class="chapter" data-level="9.1" data-path="data-rodeo.html"><a href="data-rodeo.html#joins"><i class="fa fa-check"></i><b>9.1</b> Joins</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="data-rodeo.html"><a href="data-rodeo.html#exercise-50"><i class="fa fa-check"></i><b>9.1.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="data-rodeo.html"><a href="data-rodeo.html#tidyselect"><i class="fa fa-check"></i><b>9.2</b> <code>tidyselect</code></a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="data-rodeo.html"><a href="data-rodeo.html#exercise-51"><i class="fa fa-check"></i><b>9.2.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="data-rodeo.html"><a href="data-rodeo.html#column-wise-operations-with-across"><i class="fa fa-check"></i><b>9.3</b> Column-wise Operations with <code>across()</code></a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="data-rodeo.html"><a href="data-rodeo.html#exercise-52"><i class="fa fa-check"></i><b>9.3.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="data-rodeo.html"><a href="data-rodeo.html#row-wise-operations"><i class="fa fa-check"></i><b>9.4</b> Row-wise operations</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="data-rodeo.html"><a href="data-rodeo.html#rowwise"><i class="fa fa-check"></i><b>9.4.1</b> <code>rowwise()</code></a></li>
<li class="chapter" data-level="9.4.2" data-path="data-rodeo.html"><a href="data-rodeo.html#c_across"><i class="fa fa-check"></i><b>9.4.2</b> <code>c_across()</code></a></li>
<li class="chapter" data-level="9.4.3" data-path="data-rodeo.html"><a href="data-rodeo.html#across-as-an-alternative-to-rowwise"><i class="fa fa-check"></i><b>9.4.3</b> <code>across()</code> as an alternative to <code>rowwise()</code></a></li>
<li class="chapter" data-level="9.4.4" data-path="data-rodeo.html"><a href="data-rodeo.html#ungroup"><i class="fa fa-check"></i><b>9.4.4</b> <code>ungroup()</code></a></li>
<li class="chapter" data-level="9.4.5" data-path="data-rodeo.html"><a href="data-rodeo.html#exercise-53"><i class="fa fa-check"></i><b>9.4.5</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="data-rodeo.html"><a href="data-rodeo.html#pivoting-from-wider-to-longer-and-back-again"><i class="fa fa-check"></i><b>9.5</b> Pivoting: From Wider to Longer and Back Again</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="data-rodeo.html"><a href="data-rodeo.html#pivot_longer"><i class="fa fa-check"></i><b>9.5.1</b> <code>pivot_longer()</code></a></li>
<li class="chapter" data-level="9.5.2" data-path="data-rodeo.html"><a href="data-rodeo.html#pivot_wider"><i class="fa fa-check"></i><b>9.5.2</b> <code>pivot_wider()</code></a></li>
<li class="chapter" data-level="9.5.3" data-path="data-rodeo.html"><a href="data-rodeo.html#exercise-54"><i class="fa fa-check"></i><b>9.5.3</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="data-rodeo.html"><a href="data-rodeo.html#put-that-in-your-pipe-and-smoke-it"><i class="fa fa-check"></i><b>9.6</b> Put that in your pipe and smoke it!</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="data-rodeo.html"><a href="data-rodeo.html#to-pipe-or-not-to-pipe"><i class="fa fa-check"></i><b>9.6.1</b> To pipe or not to pipe?</a></li>
<li class="chapter" data-level="9.6.2" data-path="data-rodeo.html"><a href="data-rodeo.html#supplying-an-arbitrary-argument"><i class="fa fa-check"></i><b>9.6.2</b> Supplying an Arbitrary Argument</a></li>
<li class="chapter" data-level="9.6.3" data-path="data-rodeo.html"><a href="data-rodeo.html#the-many-pipes-of-magrittr"><i class="fa fa-check"></i><b>9.6.3</b> The many pipes of <code>magrittr</code></a></li>
<li class="chapter" data-level="9.6.4" data-path="data-rodeo.html"><a href="data-rodeo.html#all-about-that-base-rs-native-pipe"><i class="fa fa-check"></i><b>9.6.4</b> All About that Base: R's "Native" Pipe</a></li>
<li class="chapter" data-level="9.6.5" data-path="data-rodeo.html"><a href="data-rodeo.html#how-does-compare-to-in-ggplot2"><i class="fa fa-check"></i><b>9.6.5</b> How does <code>%&gt;%</code> compare to <code>+</code> in <code>ggplot2</code>?</a></li>
<li class="chapter" data-level="9.6.6" data-path="data-rodeo.html"><a href="data-rodeo.html#exercise-55"><i class="fa fa-check"></i><b>9.6.6</b> Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>10</b> Poisson Regression and Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#the-poisson-distribution"><i class="fa fa-check"></i><b>10.1</b> The Poisson Distribution</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#exercise-56"><i class="fa fa-check"></i><b>10.1.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#the-poisson-regression-model"><i class="fa fa-check"></i><b>10.2</b> The Poisson Regression Model</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#exercise-57"><i class="fa fa-check"></i><b>10.2.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#whats-a-link-function"><i class="fa fa-check"></i><b>10.3</b> What's a link function?</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#exercise-58"><i class="fa fa-check"></i><b>10.3.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#dude-wheres-my-r-squared"><i class="fa fa-check"></i><b>10.4</b> Dude, where's my R-squared?</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#aic-and-bic"><i class="fa fa-check"></i><b>10.4.1</b> AIC and BIC</a></li>
<li class="chapter" data-level="10.4.2" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#deviance-and-null-deviance"><i class="fa fa-check"></i><b>10.4.2</b> Deviance and Null Deviance</a></li>
<li class="chapter" data-level="10.4.3" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#exercises-4"><i class="fa fa-check"></i><b>10.4.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#roll-your-own-poisson-mle"><i class="fa fa-check"></i><b>10.5</b> Roll Your Own Poisson MLE</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#exercise-59"><i class="fa fa-check"></i><b>10.5.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="poisson-regression-and-maximum-likelihood-estimation.html"><a href="poisson-regression-and-maximum-likelihood-estimation.html#bonus-material-stirlings-approximation"><i class="fa fa-check"></i><b>10.6</b> Bonus Material: Stirling's Approximation</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Empirical Research Methods</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="poisson-regression-and-maximum-likelihood-estimation" class="section level1 hasAnchor" number="10">
<h1><span class="header-section-number">Lesson 10</span> Poisson Regression and Maximum Likelihood Estimation<a href="poisson-regression-and-maximum-likelihood-estimation.html#poisson-regression-and-maximum-likelihood-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="the-poisson-distribution" class="section level2 hasAnchor" number="10.1">
<h2><span class="header-section-number">10.1</span> The Poisson Distribution<a href="poisson-regression-and-maximum-likelihood-estimation.html#the-poisson-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Simeon_Poisson.jpg/409px-Simeon_Poisson.jpg" width="250" alt="" />
<p class="caption">Siméon Denis Poisson</p>
</div>
<p>Suppose we wanted a probability distribution for <em>counts</em>, values in the set <span class="math inline">\(\{0, 1, 2, 3, ...\}\)</span>. One possible candidate is the Binomial<span class="math inline">\((n,p)\)</span> distribution:
<span class="math display">\[
P(X = x) = \binom{n}{x} p^x(1 - p)^{n-x}, \quad x\in \{0, 1, 2, ..., n\}.
\]</span>
If there are <span class="math inline">\(n\)</span> independent opportunities for some event to occur, and each occurrence has probability <span class="math inline">\(p\)</span>, then the Binomial<span class="math inline">\((n,p)\)</span> distribution gives us the probability of observing <span class="math inline">\(x\)</span> events. But what if we don't know <span class="math inline">\(n\)</span>? Or what if, in principle at least, there's no clear "upper bound" for our count? An example may help to make this problem clearer. If I bake a dozen cupcakes and bring them to a bake sale, then perhaps the number that I sell could be modeled as a Binomial<span class="math inline">\((12,p)\)</span> random variable.<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a> But what if we wanted a model for the <em>total</em> number of cupcakes sold in the UK on a given day? We don't know how many cupcakes were baked, so we don't know <span class="math inline">\(n\)</span>.</p>
<p>To put it another way, the Binomial distribution is really a model for <em>proportions</em>. Sure, <span class="math inline">\(X\)</span> is a count, but it's a count relative to some known <em>maximum</em> number of events. When we talk about <em>count data</em>, what we really have in mind is a situation where no such maximum exists, or where the maximum is extremely large relative to the number of events that are likely to occur. The classic probability model for data with these features is the Poisson<span class="math inline">\((\mu)\)</span> distribution:
<span class="math display">\[
P(X=x) = \frac{e^{-\mu}\mu^x}{x!}, \quad x \in \{0, 1, 2, 3, ...\}.
\]</span>
Unlike the Binomial distribution, the Poisson distribution has no upper bound: it has positive probability of spitting out any non-negative integer, no matter how large. Its single parameter <span class="math inline">\(\mu\)</span>, typically called the Poisson <em>rate</em>, can take on any <em>continuous</em> value greater than zero. This parameter quantifies the frequency with which events occur: a higher rate means we expect to see higher counts. Indeed, if <span class="math inline">\(X \sim \text{Poisson}(\mu)\)</span> then <span class="math inline">\(E[X] = \mu\)</span>; the Poisson <a href="https://expl.ai/CHAKTHR">rate parameter equals the expected count</a>. The Poisson distribution also has a feature called <em>equidispersion</em>: its <a href="https://www.economictricks.com/ps1-solutions.pdf">variance equals its mean</a>. In the exercises that follow, you'll explore some further properties of the Poisson distribution.</p>
<div id="exercise-56" class="section level3 hasAnchor" number="10.1.1">
<h3><span class="header-section-number">10.1.1</span> Exercise<a href="poisson-regression-and-maximum-likelihood-estimation.html#exercise-56" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>Use the R functions <code>dpois()</code>, <code>ppois()</code>, and <code>rpois()</code> to:
<ol style="list-style-type: lower-alpha">
<li>Plot the probability mass function of a Poisson(1), Repeat for a Poisson(3) random variable.</li>
</ol></li>
</ol>
<div class="webex-solution">
<button>
Show Hint
</button>
<p><code>geom_col()</code> is a useful alternative to <code>geom_bar()</code> that "leaves the data alone" rather than counting observations in different bins.</p>
</div>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb859"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb859-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb859-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb859-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-3" aria-hidden="true" tabindex="-1"></a>poisson_probs <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb859-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">p1 =</span> <span class="fu">dpois</span>(x, <span class="dv">1</span>), <span class="at">p3 =</span> <span class="fu">dpois</span>(x, <span class="dv">3</span>))</span>
<span id="cb859-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb859-6"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-6" aria-hidden="true" tabindex="-1"></a>pois1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(poisson_probs) <span class="sc">+</span></span>
<span id="cb859-7"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="fu">aes</span>(x, p1), <span class="at">width =</span> <span class="fl">0.05</span>) <span class="sc">+</span></span>
<span id="cb859-8"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(x, p1)) <span class="sc">+</span></span>
<span id="cb859-9"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&#39;Poisson(1) pmf&#39;</span>)</span>
<span id="cb859-10"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb859-11"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-11" aria-hidden="true" tabindex="-1"></a>pois3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(poisson_probs) <span class="sc">+</span></span>
<span id="cb859-12"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="fu">aes</span>(x, p3), <span class="at">width =</span> <span class="fl">0.05</span>) <span class="sc">+</span></span>
<span id="cb859-13"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(x, p3)) <span class="sc">+</span></span>
<span id="cb859-14"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&#39;Poisson(3) pmf&#39;</span>)</span>
<span id="cb859-15"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb859-16"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb859-16" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(pois1, pois3, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="erm-book_files/figure-html/unnamed-chunk-423-1.png" width="672" /></p>
</div>
<pre><code>(b) Simulate a large number of draws from both a Poisson(1) and Poisson(3) distribution. Check that the mean and variance of the simulation draws are approximately equal.</code></pre>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb861"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb861-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb861-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1875</span>)</span>
<span id="cb861-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb861-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">rpois</span>(<span class="fl">1e5</span>, <span class="dv">1</span>)</span>
<span id="cb861-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb861-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="st">&#39;mean&#39;</span> <span class="ot">=</span> <span class="fu">mean</span>(x1), <span class="st">&#39;var&#39;</span> <span class="ot">=</span> <span class="fu">var</span>(x1))</span></code></pre></div>
<pre><code>##         mean       var
## [1,] 0.99644 0.9950373</code></pre>
<div class="sourceCode" id="cb863"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb863-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb863-1" aria-hidden="true" tabindex="-1"></a>x3 <span class="ot">&lt;-</span> <span class="fu">rpois</span>(<span class="fl">1e5</span>, <span class="dv">3</span>)</span>
<span id="cb863-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb863-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="st">&#39;mean&#39;</span> <span class="ot">=</span> <span class="fu">mean</span>(x3), <span class="st">&#39;var&#39;</span> <span class="ot">=</span> <span class="fu">var</span>(x3))</span></code></pre></div>
<pre><code>##       mean      var
## [1,] 2.996 2.996454</code></pre>
</div>
<ol start="2" style="list-style-type: decimal">
<li>If <span class="math inline">\(X_1 \sim \text{Poisson}(\mu_1)\)</span> is independent of <span class="math inline">\(X_2 \sim \text{Poisson}(\mu_2)\)</span> then it can be shown that <span class="math inline">\(X_1 + X_2 \sim \text{Poisson}(\mu_1 + \mu_2)\)</span>. Check this property using your simulation draws from the previous part.</li>
</ol>
<div class="webex-solution">
<button>
Show Hint
</button>
<p>The <code>count()</code> function from <code>dplyr</code> is very helpful if you need to construct an empirical frequency distribution, and <code>geom_col()</code> is useful too!</p>
</div>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb865"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb865-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb865-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb865-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb865-2" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(x1, x3) <span class="sc">%&gt;%</span> </span>
<span id="cb865-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb865-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">x4 =</span> x1 <span class="sc">+</span> x3) <span class="sc">%&gt;%</span></span>
<span id="cb865-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb865-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(x4) <span class="sc">%&gt;%</span></span>
<span id="cb865-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb865-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">realization =</span> x4) <span class="sc">%&gt;%</span></span>
<span id="cb865-6"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb865-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">empirical =</span> n <span class="sc">/</span> <span class="fu">sum</span>(n),  </span>
<span id="cb865-7"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb865-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">theoretical =</span> <span class="fu">dpois</span>(realization, <span class="dv">4</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb865-8"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb865-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(realization, empirical, theoretical) <span class="sc">%&gt;%</span></span>
<span id="cb865-9"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb865-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">round</span>(<span class="dv">4</span>) <span class="sc">%&gt;%</span></span>
<span id="cb865-10"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb865-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">15</span>)</span></code></pre></div>
<pre><code>## # A tibble: 16 × 3
##    realization empirical theoretical
##          &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
##  1           0    0.0181      0.0183
##  2           1    0.0734      0.0733
##  3           2    0.148       0.146 
##  4           3    0.196       0.195 
##  5           4    0.195       0.195 
##  6           5    0.156       0.156 
##  7           6    0.104       0.104 
##  8           7    0.0596      0.0595
##  9           8    0.0289      0.0298
## 10           9    0.013       0.0132
## 11          10    0.0054      0.0053
## 12          11    0.002       0.0019
## 13          12    0.0007      0.0006
## 14          13    0.0002      0.0002
## 15          14    0.0001      0.0001
## # … with 1 more row</code></pre>
</div>
<ol start="3" style="list-style-type: decimal">
<li>For <span class="math inline">\(\mu\)</span> large, the Poisson<span class="math inline">\((\mu)\)</span> probability mass function is well-approximated by a Normal<span class="math inline">\((\mu, \mu)\)</span> density. Use <code>dnorm()</code> and <code>dpois()</code> to check the quality of this approximation for <span class="math inline">\(\mu = 20\)</span>. Can you explain why this approximation holds?</li>
</ol>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb867"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb867-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb867-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">40</span>) <span class="sc">%&gt;%</span></span>
<span id="cb867-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb867-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">normal =</span> <span class="fu">dnorm</span>(x, <span class="dv">20</span>, <span class="fu">sqrt</span>(<span class="dv">20</span>)),</span>
<span id="cb867-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb867-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">poisson =</span> <span class="fu">dpois</span>(x, <span class="dv">20</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb867-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb867-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">round</span>(<span class="dv">4</span>) <span class="sc">%&gt;%</span></span>
<span id="cb867-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb867-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">41</span>)</span></code></pre></div>
<pre><code>## # A tibble: 41 × 3
##        x normal poisson
##    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
##  1     0 0       0     
##  2     1 0       0     
##  3     2 0       0     
##  4     3 0.0001  0     
##  5     4 0.0001  0     
##  6     5 0.0003  0.0001
##  7     6 0.0007  0.0002
##  8     7 0.0013  0.0005
##  9     8 0.0024  0.0013
## 10     9 0.0043  0.0029
## 11    10 0.0073  0.0058
## 12    11 0.0118  0.0106
## 13    12 0.018   0.0176
## 14    13 0.0262  0.0271
## 15    14 0.0363  0.0387
## 16    15 0.0477  0.0516
## 17    16 0.0598  0.0646
## 18    17 0.0712  0.076 
## 19    18 0.0807  0.0844
## 20    19 0.087   0.0888
## 21    20 0.0892  0.0888
## 22    21 0.087   0.0846
## 23    22 0.0807  0.0769
## 24    23 0.0712  0.0669
## 25    24 0.0598  0.0557
## 26    25 0.0477  0.0446
## 27    26 0.0363  0.0343
## 28    27 0.0262  0.0254
## 29    28 0.018   0.0181
## 30    29 0.0118  0.0125
## 31    30 0.0073  0.0083
## 32    31 0.0043  0.0054
## 33    32 0.0024  0.0034
## 34    33 0.0013  0.002 
## 35    34 0.0007  0.0012
## 36    35 0.0003  0.0007
## 37    36 0.0001  0.0004
## 38    37 0.0001  0.0002
## 39    38 0       0.0001
## 40    39 0       0.0001
## 41    40 0       0</code></pre>
<p>Let <span class="math inline">\(X \sim \text{Poisson}(n)\)</span>. By the result from the preceding part, we can view <span class="math inline">\(X\)</span> as the sum of <span class="math inline">\(n\)</span> independent and identically distributed Poisson<span class="math inline">\((1)\)</span> random variables <span class="math inline">\(X_1, X_2, ..., X_n\)</span>. Because these are Poisson, each has mean and variance equal to one. Thus, by the central limit theorem
<span class="math display">\[
\sqrt{n}(\bar{X}_n - 1) \rightarrow_d \text{N}(0,1)
\]</span>
so for large <span class="math inline">\(n\)</span> we have the approximation <span class="math inline">\(\sqrt{n}(\bar{X}_n - 1) \approx Z\)</span> where <span class="math inline">\(Z \sim\text{N}(0,1)\)</span>. Re-arranging,
<span class="math display">\[
n \bar{X}_n \approx  n + \sqrt{n} Z \sim N(n, n)
\]</span>
and <span class="math inline">\(n\bar{X}_n\)</span> is precisely the random variable that wanted to approximate: a Poisson<span class="math inline">\((n)\)</span>.</p>
</div>
<ol start="4" style="list-style-type: decimal">
<li>The Poisson<span class="math inline">\((\mu)\)</span> distribution is closely related to the Binomial distribution. In fact, the Poisson<span class="math inline">\((\mu)\)</span> probability mass function is the <em>limit</em> of the Binomial<span class="math inline">\((n,p)\)</span> probability mass function as <span class="math inline">\(n\rightarrow \infty\)</span> and <span class="math inline">\(p \rightarrow 0\)</span> such that <span class="math inline">\(np\rightarrow \mu\)</span>. In other words, if <span class="math inline">\(p\)</span> is small and <span class="math inline">\(n\)</span> is large, then the Binomial<span class="math inline">\((n,p)\)</span> distribution is extremely similar to the Poisson<span class="math inline">\((np)\)</span> distribution. Use <code>dbinom()</code> and <code>dpois()</code> to verify the quality of this approximation for <span class="math inline">\(n = 1000\)</span> and <span class="math inline">\(p = 0.005\)</span>.</li>
</ol>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb869"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb869-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb869-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb869-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb869-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fl">0.005</span></span>
<span id="cb869-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb869-3" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">16</span>) <span class="sc">%&gt;%</span></span>
<span id="cb869-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb869-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">poisson =</span> <span class="fu">dpois</span>(x, n <span class="sc">*</span> p), <span class="at">binomial =</span> <span class="fu">dbinom</span>(x, n, p)) <span class="sc">%&gt;%</span></span>
<span id="cb869-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb869-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">round</span>(<span class="dv">4</span>) <span class="sc">%&gt;%</span></span>
<span id="cb869-6"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb869-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">40</span>)</span></code></pre></div>
<pre><code>## # A tibble: 17 × 3
##        x poisson binomial
##    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;
##  1     0  0.0067   0.0067
##  2     1  0.0337   0.0334
##  3     2  0.0842   0.0839
##  4     3  0.140    0.140 
##  5     4  0.176    0.176 
##  6     5  0.176    0.176 
##  7     6  0.146    0.147 
##  8     7  0.104    0.105 
##  9     8  0.0653   0.0652
## 10     9  0.0363   0.0361
## 11    10  0.0181   0.018 
## 12    11  0.0082   0.0081
## 13    12  0.0034   0.0034
## 14    13  0.0013   0.0013
## 15    14  0.0005   0.0005
## 16    15  0.0002   0.0002
## 17    16  0        0</code></pre>
</div>
<ol start="5" style="list-style-type: decimal">
<li>In this exercise, I hope to convince you that computing the Poisson probability mass function is harder than it looks! For this part you will need to use the R functions <code>factorial()</code> and, later on, <code>lfactorial()</code>.
<ol style="list-style-type: lower-alpha">
<li>Suppose that <span class="math inline">\(X \sim \text{Poisson}(171)\)</span>. Calculate the probability that <span class="math inline">\(X\)</span> equals its mean two different ways: first using <code>dpois()</code> and second by direct calculation using the Poisson probability mass function from above. Why do your results disagree?</li>
</ol></li>
</ol>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb871"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb871-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb871-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="st">&#39;by hand&#39;</span> <span class="ot">=</span> <span class="fu">exp</span>(<span class="sc">-</span><span class="dv">171</span>) <span class="sc">*</span> <span class="dv">171</span><span class="sc">^</span><span class="dv">171</span> <span class="sc">/</span> <span class="fu">factorial</span>(<span class="dv">171</span>), <span class="st">&#39;dpois&#39;</span> <span class="ot">=</span> <span class="fu">dpois</span>(<span class="dv">171</span>, <span class="dv">171</span>))</span></code></pre></div>
<pre><code>##    by hand      dpois 
##        NaN 0.03049301</code></pre>
</div>
<pre><code>(b) Write out an expression for the *natural log* of the Poisson probability mass function. Can you think of a way to use this expression to solve the problem you encountered in the preceding part? </code></pre>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb874"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb874-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb874-1" aria-hidden="true" tabindex="-1"></a>log_prob <span class="ot">&lt;-</span> <span class="dv">171</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">171</span>) <span class="sc">-</span> <span class="dv">171</span> <span class="sc">-</span> <span class="fu">lfactorial</span>(<span class="dv">171</span>)</span>
<span id="cb874-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb874-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="st">&#39;by hand&#39;</span> <span class="ot">=</span> <span class="fu">exp</span>(log_prob), <span class="st">&#39;dpois&#39;</span> <span class="ot">=</span>  <span class="fu">dpois</span>(<span class="dv">171</span>, <span class="dv">171</span>))</span></code></pre></div>
<pre><code>##    by hand      dpois 
## 0.03049301 0.03049301</code></pre>
</div>
</div>
</div>
<div id="the-poisson-regression-model" class="section level2 hasAnchor" number="10.2">
<h2><span class="header-section-number">10.2</span> The Poisson Regression Model<a href="poisson-regression-and-maximum-likelihood-estimation.html#the-poisson-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Counts are by definition positive or zero, but a linear regression model of the form <span class="math inline">\(Y = \alpha + \beta X + \epsilon\)</span> will <em>necessarily</em> make negative predictions for <span class="math inline">\(Y\)</span> for certain values of <span class="math inline">\(X\)</span>. (A straight line with that isn't perfectly flat will eventually cross the x-axis.) We might try to solve this problem by running a regression with <span class="math inline">\(\log Y\)</span> in place of <span class="math inline">\(Y\)</span>. But just like the <a href="https://en.wikipedia.org/wiki/There_Was_an_Old_Lady_Who_Swallowed_a_Fly">old lady who swallowed a fly</a>, this would leave us with yet another problem to solve: a count of zero makes <span class="math inline">\(\log Y\)</span> equal negative infinity! This might motivate us to add one to our counts before taking logs, a perfectly reasonable idea. But at this point we have a very different model than the one we started with.</p>
<p>A more elegant solution is to start off by writing down a <em>probability model</em> that guarantees our predictions will take values in the appropriate range. For count outcomes, the most popular model of this form is Poisson regression.<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> The idea is fairly simple: we model <span class="math inline">\(Y_i\)</span> as a Poisson random variable <span class="math inline">\(\mu_i\)</span> where <span class="math inline">\(\mu_i\)</span> is a positive function of <span class="math inline">\(X_i\)</span>. The "canonical" version of Poisson regression posits a linear relationship between <span class="math inline">\(X_i\)</span> and <span class="math inline">\(\log(\mu_i)\)</span>, namely
<span class="math display">\[
Y_i|X_i \sim \text{indep. Poisson}(\mu_i), \quad \mu_i \equiv \exp(X_i&#39;\beta).
\]</span>
Using what we learned about the Poisson distribution from above, we can write down the (conditional) likelihood function for this problem as follows:
<span class="math display">\[
L(\beta) = \prod_{i=1}^n f(Y_i|X_i,\beta) =  \prod_{i=1}^n \frac{e^{-\mu_i}\mu_i^{Y_i}}{Y_i!}
\]</span>
Remember that the likelihood is a function of the <em>parameters</em> that holds the <em>data fixed</em>. The likelihood for this problem takes the form of a product because our observations of <span class="math inline">\(Y_i\)</span> are independent conditional on <span class="math inline">\(X_i\)</span> so that
<span class="math display">\[
f(Y_1, Y_2, ..., Y_n|X_1, X_2, ..., X_n) = f(Y_1|X_1) \times f(Y_2|X_2) \times \cdots \times f(Y_n|X_n).
\]</span>
Taking logarithms of the likelihood, we obtain the (conditional) log-likelihood as follows:
<span class="math display">\[
\begin{aligned}
\ell(\beta) &amp;= \sum_{i=1}^n \left[Y_i \log(\mu_i) - \mu_i - \log(Y_i!)\right]\\
&amp;=\sum_{i=1}^n \left[ Y_i (X_i&#39;\beta) - \exp(X_i&#39;\beta) - \log(Y_i!) \right]
\end{aligned}
\]</span>
It's easy to estimate the parameter <span class="math inline">\(\beta\)</span> in this model using the <code>glm()</code> function in R. But before we learn about this we need some data from a Poisson regression model! You'll generate some in the following exercise.</p>
<div id="exercise-57" class="section level3 hasAnchor" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> Exercise<a href="poisson-regression-and-maximum-likelihood-estimation.html#exercise-57" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Simulate 1000 observations from a Poisson regression model in which <span class="math inline">\(\mu_i = \exp(\alpha + \beta X_i)\)</span> with <span class="math inline">\(\alpha = 0.2\)</span> and <span class="math inline">\(\beta = 0.6\)</span>. Draw your <span class="math inline">\(X_i\)</span> values form a standard normal distribution, store your results as columns named <code>x</code> and <code>y</code> in a tibble called <code>pois_dat</code>, and plot your simulated observations. I suggest using jittering to make the plot easier to read.</p>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb876"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb876-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb876-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb876-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb876-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1983</span>)</span>
<span id="cb876-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb876-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fl">1e3</span></span>
<span id="cb876-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb876-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb876-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb876-5" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fl">0.2</span></span>
<span id="cb876-6"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb876-6" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fl">0.6</span></span>
<span id="cb876-7"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb876-7" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">exp</span>(a <span class="sc">+</span> b <span class="sc">*</span> x)</span>
<span id="cb876-8"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb876-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rpois</span>(n, mu)</span>
<span id="cb876-9"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb876-9" aria-hidden="true" tabindex="-1"></a>pois_dat <span class="ot">&lt;-</span> <span class="fu">tibble</span>(x, y)</span>
<span id="cb876-10"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb876-10" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(x, y, a, b, mu, n) <span class="co"># Clean up!</span></span>
<span id="cb876-11"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb876-11" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(pois_dat, <span class="fu">aes</span>(x, y)) <span class="sc">+</span></span>
<span id="cb876-12"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb876-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">height =</span> <span class="fl">0.2</span>) </span></code></pre></div>
<p><img src="erm-book_files/figure-html/unnamed-chunk-430-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="whats-a-link-function" class="section level2 hasAnchor" number="10.3">
<h2><span class="header-section-number">10.3</span> What's a link function?<a href="poisson-regression-and-maximum-likelihood-estimation.html#whats-a-link-function" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To fit a Poisson regression in R we use the <code>glm()</code> function, much as we did for logistic regression in an earlier lesson. The only substantive difference is that we set <code>family = poisson(link = 'log')</code> rather than <code>family = binomial(link = 'logit')</code>. But this raises a question that we've avoided so far: what's this "link" thing that we keep having to specify inside of <code>glm()</code>?</p>
<p>A <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">generalized linear model</a> is a <em>generalization</em> of linear regression that allows to model a <em>non-linear</em> predictive relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>. In the Poisson regression model from above, <span class="math inline">\(Y_i|X_i \sim \text{Poisson}\big( \exp(X_i&#39;\beta)\big)\)</span>. Since the rate parameter of a Poisson random variable equals the mean of that random variable, our model posits that
<span class="math display">\[
E[Y_i|X_i] = \exp(X_i&#39;\beta) \quad
\text{ or equivalently } \quad \log \left( E[Y_i|X_i] \right) = X_i&#39;\beta.
\]</span>
Abstracting slightly, what we have is a model in which <span class="math inline">\(g\left(E[Y_i|X_i] \right)\)</span> equals <span class="math inline">\(X_i&#39;\beta\)</span> for some function <span class="math inline">\(g(\cdot)\)</span>. You've already seen two other models that fit into this framework: linear regression has <span class="math inline">\(g(z) = z\)</span> and logistic regression has <span class="math inline">\(g(z) = \log[z/(1 - z)]\)</span>. In generalized linear model terminology, the function <span class="math inline">\(g(\cdot)\)</span> is called the <strong>link function</strong> while <span class="math inline">\(X_i&#39;\beta\)</span> is called the <strong>linear predictor</strong>. To specify a <code>glm()</code> in R we provide the <code>family</code>, the probability distribution of <span class="math inline">\(Y\)</span> e.g. <code>binomial</code> or <code>poisson</code>, and the link function. The <code>formula</code> inside of <code>glm()</code> is where we specify the regressors <span class="math inline">\(X_i\)</span> that enter the linear predictor.</p>
<p>When we make <em>predictions</em> based on a generalized linear model, we have two options. We can either ask for predictions on the scale of the <em>linear predictor</em> <span class="math inline">\(X_i&#39;\beta\)</span>, the default behavior of <code>predict()</code> when applied to a <code>glm()</code> object, or on the scale of the <em>response</em> <span class="math inline">\(Y_i\)</span> by setting <code>type = 'response'</code> in <code>predict()</code> or <code>type.predict = 'response'</code> in <code>augment()</code> from <code>broom</code>. Typically we're most interested in predictions on the scale of <span class="math inline">\(Y_i\)</span>. If we want <em>residuals</em> for a <code>glm()</code> object there are many different options. Setting <code>type = 'response'</code> gives residuals computed as the difference between <span class="math inline">\(Y_i\)</span> and the prediction <span class="math inline">\(\widehat{Y}_i\)</span> that we would obtain from <code>predict()</code> with <code>type = 'response'</code>.</p>
<p>At this point you know quite a lot about R. So rather than providing you with examples of how all the skills you've learned so far can be applied to Poisson regression, I'll ask you to discover this for yourself in the following exercises!</p>
<div id="exercise-58" class="section level3 hasAnchor" number="10.3.1">
<h3><span class="header-section-number">10.3.1</span> Exercise<a href="poisson-regression-and-maximum-likelihood-estimation.html#exercise-58" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>Fit both a linear regression, <code>lreg</code>, and a Poisson regression with a log link function, <code>preg</code>, to your simulated data from the preceding exercise. Display your results in a nicely-formatted table of regression output.</li>
</ol>
<div class="webex-solution">
<button>
Solution
</button>
<div class="sourceCode" id="cb877"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb877-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb877-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(modelsummary)</span>
<span id="cb877-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb877-2" aria-hidden="true" tabindex="-1"></a>lreg <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> pois_dat)</span>
<span id="cb877-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb877-3" aria-hidden="true" tabindex="-1"></a>preg <span class="ot">&lt;-</span> <span class="fu">glm</span>(y <span class="sc">~</span> x, <span class="at">family =</span> <span class="fu">poisson</span>(<span class="at">link =</span> <span class="st">&#39;log&#39;</span>), <span class="at">data =</span> pois_dat)</span>
<span id="cb877-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb877-4" aria-hidden="true" tabindex="-1"></a><span class="fu">modelsummary</span>(<span class="fu">list</span>(<span class="st">&#39;OLS&#39;</span> <span class="ot">=</span> lreg, <span class="st">&#39;Poisson&#39;</span> <span class="ot">=</span> preg))</span></code></pre></div>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
OLS
</th>
<th style="text-align:center;">
Poisson
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:center;">
1.498
</td>
<td style="text-align:center;">
0.229
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(0.042)
</td>
<td style="text-align:center;">
(0.030)
</td>
</tr>
<tr>
<td style="text-align:left;">
x
</td>
<td style="text-align:center;">
0.904
</td>
<td style="text-align:center;">
0.601
</td>
</tr>
<tr>
<td style="text-align:left;box-shadow: 0px 1px">
</td>
<td style="text-align:center;box-shadow: 0px 1px">
(0.042)
</td>
<td style="text-align:center;box-shadow: 0px 1px">
(0.026)
</td>
</tr>
<tr>
<td style="text-align:left;">
Num.Obs.
</td>
<td style="text-align:center;">
1000
</td>
<td style="text-align:center;">
1000
</td>
</tr>
<tr>
<td style="text-align:left;">
R2
</td>
<td style="text-align:center;">
0.316
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
R2 Adj.
</td>
<td style="text-align:center;">
0.315
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
AIC
</td>
<td style="text-align:center;">
3391.8
</td>
<td style="text-align:center;">
2922.9
</td>
</tr>
<tr>
<td style="text-align:left;">
BIC
</td>
<td style="text-align:center;">
3406.6
</td>
<td style="text-align:center;">
2932.8
</td>
</tr>
<tr>
<td style="text-align:left;">
Log.Lik.
</td>
<td style="text-align:center;">
−1692.919
</td>
<td style="text-align:center;">
−1459.472
</td>
</tr>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:center;">
460.194
</td>
<td style="text-align:center;">
520.670
</td>
</tr>
<tr>
<td style="text-align:left;">
RMSE
</td>
<td style="text-align:center;">
1.32
</td>
<td style="text-align:center;">
1.07
</td>
</tr>
</tbody>
</table>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Plot the two regression models from the preceding part along with the data. As above I suggest using jittering to make the plot easier to read.</li>
</ol>
<div class="webex-solution">
<button>
Solution
</button>
<div class="sourceCode" id="cb878"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb878-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb878-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(pois_dat, <span class="fu">aes</span>(x, y)) <span class="sc">+</span></span>
<span id="cb878-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb878-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">height =</span> <span class="fl">0.2</span>) <span class="sc">+</span> </span>
<span id="cb878-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb878-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&#39;glm&#39;</span>, <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">family =</span> <span class="st">&quot;poisson&quot;</span>), <span class="at">formula =</span> y <span class="sc">~</span> x) <span class="sc">+</span></span>
<span id="cb878-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb878-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&#39;lm&#39;</span>, <span class="at">formula =</span> y <span class="sc">~</span> x)</span></code></pre></div>
<p><img src="erm-book_files/figure-html/unnamed-chunk-432-1.png" width="672" /></p>
</div>
<ol start="3" style="list-style-type: decimal">
<li>Use the results of <code>lreg</code> and <code>preg</code> to predict <span class="math inline">\(Y_i\)</span> when <span class="math inline">\(X_i = -2\)</span>. Comment on your results.</li>
</ol>
<div class="webex-solution">
<button>
Solution
</button>
<div class="sourceCode" id="cb879"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb879-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb879-1" aria-hidden="true" tabindex="-1"></a>mydat <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="sc">-</span><span class="dv">2</span>)</span>
<span id="cb879-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb879-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(preg, <span class="at">newdata =</span> mydat, <span class="at">type =</span> <span class="st">&#39;response&#39;</span>)</span></code></pre></div>
<pre><code>##         1 
## 0.3782432</code></pre>
<div class="sourceCode" id="cb881"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb881-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb881-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(lreg, <span class="at">newdata =</span> mydat) <span class="co"># don&#39;t need to set type for linear regression!</span></span></code></pre></div>
<pre><code>##          1 
## -0.3090112</code></pre>
</div>
<ol start="4" style="list-style-type: decimal">
<li>Verify numerically that the residuals, <code>type = 'response'</code>, of <code>preg</code> sum to zero and are uncorrelated with <code>x</code>.</li>
</ol>
<div class="webex-solution">
<button>
Solution
</button>
<div class="sourceCode" id="cb883"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb883-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb883-1" aria-hidden="true" tabindex="-1"></a>u <span class="ot">&lt;-</span> <span class="fu">residuals</span>(preg, <span class="at">type =</span> <span class="st">&#39;response&#39;</span>)</span>
<span id="cb883-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb883-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(u)</span></code></pre></div>
<pre><code>## [1] -1.373208e-11</code></pre>
<div class="sourceCode" id="cb885"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb885-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb885-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(u, pois_dat<span class="sc">$</span>x)</span></code></pre></div>
<pre><code>## [1] 4.785601e-12</code></pre>
</div>
<ol start="5" style="list-style-type: decimal">
<li>Verify numerically that the average partial effect of <code>x</code> in your fitted Poisson regression model <code>preg</code> equals the sample mean of <span class="math inline">\(Y_i\)</span> multiplied by the estimated coefficient <span class="math inline">\(\widehat{\beta}\)</span>. Compare this to the corresponding OLS coefficient. (See <a href="https://www.economictricks.com/ps1-solutions.pdf">here</a> for further discussion.)</li>
</ol>
<div class="webex-solution">
<button>
Solution
</button>
<div class="sourceCode" id="cb887"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb887-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb887-1" aria-hidden="true" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">mean</span>(<span class="fu">predict</span>(preg, <span class="at">type =</span> <span class="st">&#39;response&#39;</span>)) <span class="sc">*</span> <span class="fu">coef</span>(preg)[<span class="dv">2</span>],</span>
<span id="cb887-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb887-2" aria-hidden="true" tabindex="-1"></a>          <span class="fu">mean</span>(pois_dat<span class="sc">$</span>y) <span class="sc">*</span> <span class="fu">coef</span>(preg)[<span class="dv">2</span>])</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
</div>
<ol start="6" style="list-style-type: decimal">
<li>Fit a Poisson regression model with <em>only an intercept</em> to your simulation data from above and call the result <code>preg0</code>. Does the estimated coefficient make sense? Explain briefly.</li>
</ol>
<div class="webex-solution">
<button>
Solution
</button>
<div class="sourceCode" id="cb889"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb889-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb889-1" aria-hidden="true" tabindex="-1"></a>preg0 <span class="ot">&lt;-</span> <span class="fu">glm</span>(y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">family =</span> <span class="fu">poisson</span>(<span class="at">link =</span> <span class="st">&#39;log&#39;</span>), <span class="at">data =</span> pois_dat)</span>
<span id="cb889-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb889-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="fu">coef</span>(preg0),  <span class="fu">log</span>(<span class="fu">mean</span>(pois_dat<span class="sc">$</span>y)))</span></code></pre></div>
<pre><code>## (Intercept)             
##   0.4226499   0.4226499</code></pre>
</div>
<ol start="7" style="list-style-type: decimal">
<li>To estimate the Poisson regression coefficients in our model from above, <code>glm()</code> maximizes the log likelihood function over the parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. This is because our model specified <span class="math inline">\(\mu_i = \exp(\alpha + \beta X_i)\)</span>. Now suppose that we ignored <code>x</code> completely and wrote down a likelihood with <em>as many parameters as observations</em> <span class="math inline">\(\mu_1, \mu_2, ..., \mu_n\)</span>. This is called the <strong>saturated model</strong>. What is the maximum likelihood estimator for this vector of parameters? What is the value of the maximized log-likelihood function?</li>
</ol>
<div class="webex-solution">
<button>
Show Solution
</button>
<p>The solution sets <span class="math inline">\(Y_i = \mu_i\)</span> for each <span class="math inline">\(i\)</span>. Notice that we need to treat <span class="math inline">\(y \log(y)\)</span> as zero for <span class="math inline">\(y = 0\)</span> in the calculation that follows:</p>
<div class="sourceCode" id="cb891"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb891-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb891-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magrittr)</span>
<span id="cb891-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb891-2" aria-hidden="true" tabindex="-1"></a>pois_dat <span class="sc">%$%</span> </span>
<span id="cb891-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb891-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(<span class="fu">ifelse</span>(y <span class="sc">&gt;</span> <span class="dv">0</span>, y <span class="sc">*</span> <span class="fu">log</span>(y), <span class="dv">0</span>) <span class="sc">-</span> y <span class="sc">-</span> <span class="fu">lfactorial</span>(y))</span></code></pre></div>
<pre><code>## [1] -889.1677</code></pre>
</div>
</div>
</div>
<div id="dude-wheres-my-r-squared" class="section level2 hasAnchor" number="10.4">
<h2><span class="header-section-number">10.4</span> Dude, where's my R-squared?<a href="poisson-regression-and-maximum-likelihood-estimation.html#dude-wheres-my-r-squared" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Remiremont_-_square_du_170e-R.-I._-_panneau_01.jpg/640px-Remiremont_-_square_du_170e-R.-I._-_panneau_01.jpg" width="250" alt="" />
<p class="caption">Square du R</p>
</div>
<p>Recall that the <code>glance()</code> function from the <code>broom</code> package extracts the various measures of "fit" from an estimated model. Applying it to <code>preg</code> from above gives the following:</p>
<div class="sourceCode" id="cb893"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb893-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb893-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(preg)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 8
##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs
##           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;
## 1         1668.     999 -1459. 2923. 2933.    1141.         998  1000</code></pre>
<p>If we try the same with a fitted logistic regression model, we'll obtain the same summary statistics:</p>
<div class="sourceCode" id="cb895"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb895-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb895-1" aria-hidden="true" tabindex="-1"></a>two_truths <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&#39;https://ditraglia.com/data/two-truths-and-a-lie-2022-cleaned.csv&#39;</span>)</span>
<span id="cb895-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb895-2" aria-hidden="true" tabindex="-1"></a>two_truths_reg <span class="ot">&lt;-</span> <span class="fu">glm</span>(guessed_right <span class="sc">~</span> certainty, <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">&#39;logit&#39;</span>),</span>
<span id="cb895-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb895-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">data =</span> two_truths)</span>
<span id="cb895-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb895-4" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(two_truths_reg) </span></code></pre></div>
<pre><code>## # A tibble: 1 × 8
##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs
##           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;
## 1          69.2      49  -33.8  71.6  75.5     67.6          48    50</code></pre>
<p>Who are these strange measures of fit, and what have they done with my R-squared?! Recall that the R-squared of a linear regression model is defined as
<span class="math display">\[
R^2 = 1 - \frac{\sum_{i=1}^n \widehat{\epsilon}_i^2}{\sum_{i=1}^n (Y_i - \bar{Y})^2}.
\]</span>
where <span class="math inline">\(\widehat{\epsilon}_i = Y_i - \widehat{Y}_i\)</span> and <span class="math inline">\(\widehat{Y}_i = X_i&#39;\widehat{\beta}\)</span>. The R-squared is a <em>unitless</em> quantity between zero and one that measures how closely our observations cluster around the regression line (or hyperplane). Larger values mean that they cluster more tightly around the line; smaller values mean that they cluster less tightly. A related measure is the <em>residual standard deviation</em>, aka the standard error of the regression:
<span class="math display">\[
\widehat{\sigma} = \sqrt{\frac{\sum_{i=1}^n \widehat{\epsilon}_i^2}{n-k}}.
\]</span>
Notice that <span class="math inline">\(\widehat{\sigma} \approx S_Y\sqrt{1 - R^2}\)</span>, where <span class="math inline">\(S_Y\)</span> is the sample standard deviation of <span class="math inline">\(Y\)</span>. Whereas R-squared is unitless, the residual standard deviation has the same units as <span class="math inline">\(Y\)</span>, giving it a more natural interpretation.</p>
<div id="aic-and-bic" class="section level3 hasAnchor" number="10.4.1">
<h3><span class="header-section-number">10.4.1</span> AIC and BIC<a href="poisson-regression-and-maximum-likelihood-estimation.html#aic-and-bic" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Both R-squared and residual standard deviation are measures of <em>in-sample fit</em>. They tell us something about how well a linear regression model predicts the <span class="math inline">\(Y\)</span> observations <em>that were used to estimate its coefficients</em>. Unfortunately in-sample fit can given an <a href="https://en.wikipedia.org/wiki/Overfitting">extremely misleading impression</a> of how well a model will predict out-of-sample. (Remember that your R-squared can <em>never decrease</em> even if the predictors you add to your model are literally irrelevant!) But even if we are content to report a measure of in-sample fit, neither R-squared nor the residual standard deviation are immediately applicable to generalized linear models. For this reason the measures of fit calculated by <code>glm()</code> are instead based on the <em>maximized log-likelihood</em>. This is what the column <code>logLik</code> from our <code>glance()</code> output from above reports:</p>
<div class="sourceCode" id="cb897"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb897-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb897-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(preg)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 8
##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs
##           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;
## 1         1668.     999 -1459. 2923. 2933.    1141.         998  1000</code></pre>
<p>We can extract this quantity from a fitted <code>glm()</code> object directly by using the <code>logLik()</code> function. For example:</p>
<div class="sourceCode" id="cb899"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb899-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb899-1" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(preg)</span></code></pre></div>
<pre><code>## &#39;log Lik.&#39; -1459.472 (df=2)</code></pre>
<p>Just like R-squared, the maximized log-likelihood can never decreases as we add more predictors to a model, even if they're completely irrelevant. For example, we can compare the log-likelihood of the "null model" <code>preg0</code> that contains only an intercept, to that of <code>preg</code>, and to the likelihood of the "saturated" model that contains a separate coefficient for each y-observation, computed in the exercise above:</p>
<div class="sourceCode" id="cb901"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb901-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb901-1" aria-hidden="true" tabindex="-1"></a>ll_fitted <span class="ot">&lt;-</span> <span class="fu">logLik</span>(preg)</span>
<span id="cb901-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb901-2" aria-hidden="true" tabindex="-1"></a>ll_null <span class="ot">&lt;-</span> <span class="fu">logLik</span>(preg0)</span>
<span id="cb901-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb901-3" aria-hidden="true" tabindex="-1"></a>ll_saturated <span class="ot">&lt;-</span> pois_dat <span class="sc">%$%</span> </span>
<span id="cb901-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb901-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(<span class="fu">ifelse</span>(y <span class="sc">&gt;</span> <span class="dv">0</span>, y <span class="sc">*</span> <span class="fu">log</span>(y), <span class="dv">0</span>) <span class="sc">-</span> y <span class="sc">-</span> <span class="fu">lfactorial</span>(y))</span>
<span id="cb901-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb901-5" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="st">&#39;null&#39;</span> <span class="ot">=</span> ll_null, <span class="st">&#39;fitted&#39;</span> <span class="ot">=</span> ll_fitted, <span class="st">&#39;saturated&#39;</span> <span class="ot">=</span> ll_saturated)</span></code></pre></div>
<pre><code>##       null     fitted  saturated 
## -1723.2250 -1459.4717  -889.1677</code></pre>
<p>But just because the log-likelihood has increased, that doesn't mean we have a better predictive model. As you will show in the exercise below, both <code>ll_fitted</code> and <code>ll_saturated</code> are larger than the log-likelihood evaluated at the <em>true</em> model parameters <span class="math inline">\(\alpha = 0.2\)</span> and <span class="math inline">\(\beta = 0.6\)</span> from our simulation design! But clearly if we wanted to predict new data from the model, there's no way to improve upon the true parameter values.</p>
<p>This is the problem that <em>information criteria</em> attempt to solve. We don't have time to do this subject justice here. (For more details, see my <a href="http://ditraglia.com/econ722/main.pdf">lecture notes</a> and <a href="http://ditraglia.com/econ722/slides/econ722slides.pdf">slides</a>.) To make a long story short, information criterion such as <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">Akaike's Information Criterion (AIC)</a> and the <a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">Bayesian Information Criterion (BIC)</a> <em>penalize</em> the maximized log-likelihood based on the number of free parameters in the model: the more parameters, the bigger the penalty. When given a <code>glm()</code> model as input, the R functions <code>AIC()</code> and <code>BIC()</code> compute the following:
<span class="math display">\[
\begin{aligned}
\text{AIC} &amp;\equiv -2 \left[\text{(Log-Likelihood)} - \text{(#Parameters)} \right] \\
\text{BIC} &amp;\equiv -2 \left[\text{(Log-Likelihood)} - \frac{1}{2}\text{(#Parameters)} \times \log\text{(#Observations)} \right]
\end{aligned}
\]</span>
The multiplication by <span class="math inline">\(-2\)</span> is conventional but arbitrary. Be careful: some books and software packages use a different scaling! Now we can compute the AIC and BIC three different ways, using <code>AIC()</code> and <code>BIC()</code> versus <code>glance()</code> versus "by hand," to make sure that they agree:</p>
<div class="sourceCode" id="cb903"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb903-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb903-1" aria-hidden="true" tabindex="-1"></a>n_params <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">coef</span>(preg))</span>
<span id="cb903-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb903-2" aria-hidden="true" tabindex="-1"></a>n_obs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(pois_dat) </span>
<span id="cb903-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb903-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb903-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb903-4" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="st">&#39;AIC&#39;</span> <span class="ot">=</span> <span class="fu">AIC</span>(preg), </span>
<span id="cb903-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb903-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;glance&#39;</span> <span class="ot">=</span> <span class="fu">glance</span>(preg)<span class="sc">$</span>AIC,</span>
<span id="cb903-6"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb903-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;by hand&#39;</span> <span class="ot">=</span> <span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> (<span class="fu">logLik</span>(preg) <span class="sc">-</span> n_params))</span></code></pre></div>
<pre><code>##      AIC   glance  by hand 
## 2922.943 2922.943 2922.943</code></pre>
<div class="sourceCode" id="cb905"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb905-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb905-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="st">&#39;BIC&#39;</span> <span class="ot">=</span> <span class="fu">BIC</span>(preg), </span>
<span id="cb905-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb905-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;glance&#39;</span> <span class="ot">=</span> <span class="fu">glance</span>(preg)<span class="sc">$</span>BIC,</span>
<span id="cb905-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb905-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;by hand&#39;</span> <span class="ot">=</span> <span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> (<span class="fu">logLik</span>(preg) <span class="sc">-</span> <span class="fl">0.5</span> <span class="sc">*</span> n_params <span class="sc">*</span> <span class="fu">log</span>(n_obs)))</span></code></pre></div>
<pre><code>##      BIC   glance  by hand 
## 2932.759 2932.759 2932.759</code></pre>
</div>
<div id="deviance-and-null-deviance" class="section level3 hasAnchor" number="10.4.2">
<h3><span class="header-section-number">10.4.2</span> Deviance and Null Deviance<a href="poisson-regression-and-maximum-likelihood-estimation.html#deviance-and-null-deviance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are two more measures of fit that appear in the summary output from <code>glance()</code> when applied to a <code>glm()</code> object. The <strong>deviance,</strong> also known as the <strong>residual deviance</strong> is defined as two times the difference between the log likelihood of the saturated model minus that of the fitted model:</p>
<div class="sourceCode" id="cb907"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb907-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb907-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Deviance, aka residual deviance</span></span>
<span id="cb907-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb907-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="st">&#39;by hand&#39;</span> <span class="ot">=</span> <span class="dv">2</span> <span class="sc">*</span> (ll_saturated <span class="sc">-</span> ll_fitted), </span>
<span id="cb907-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb907-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;deviance&#39;</span> <span class="ot">=</span> <span class="fu">glance</span>(preg)<span class="sc">$</span>deviance)</span></code></pre></div>
<pre><code>##  by hand deviance 
## 1140.608 1140.608</code></pre>
<p>whereas the <strong>null deviance</strong> is the same quantity except with the log-likelihood of the <em>null</em> model in place of the fitted model, i.e. the model that includes only an intercept:</p>
<div class="sourceCode" id="cb909"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb909-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb909-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Null deviance</span></span>
<span id="cb909-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb909-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="st">&#39;by hand&#39;</span> <span class="ot">=</span> <span class="dv">2</span> <span class="sc">*</span> (ll_saturated <span class="sc">-</span> ll_null), </span>
<span id="cb909-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb909-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;null deviance&#39;</span> <span class="ot">=</span> <span class="fu">glance</span>(preg)<span class="sc">$</span>null.deviance)</span></code></pre></div>
<pre><code>##       by hand null deviance 
##      1668.115      1668.115</code></pre>
<p>We won't delve into these quantities in any detail, but it's worth making two points. First, notice that both the deviance and the null deviance equal a constant multiplied by the log of a likelihood ratio statistic. Second, it turns out that the deviance of a linear regression model is proportional to the sum of squared residuals. As such we can think of the deviance as a "version" of the RSS for generalized linear models.</p>
</div>
<div id="exercises-4" class="section level3 hasAnchor" number="10.4.3">
<h3><span class="header-section-number">10.4.3</span> Exercises<a href="poisson-regression-and-maximum-likelihood-estimation.html#exercises-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>Write a function called <code>pois_ll()</code> that evaluates the log-likelihood function for <code>pois_dat</code>. Your function should take a single argument <code>params</code>. This is a vector whose first element is the value of <span class="math inline">\(\alpha\)</span> and whose second element is the value of <span class="math inline">\(\beta\)</span>. It should return the log-likelihood of the model <span class="math inline">\(Y_i|X_i \sim \text{Poisson}(\mu_i)\)</span> for <span class="math inline">\(\mu_i= \exp(\alpha + \beta X_i)\)</span> where <span class="math inline">\(\{(Y_i, X_i)\}_{i=1}^n\)</span> are the simulation draws <code>x</code> and <code>y</code> from <code>pois_dat</code>. To make sure that your function is working correctly, evaluate it at the appropriate parameter values, check it against <code>logLik(preg)</code> and <code>logLik(preg0)</code> from above.</li>
</ol>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb911"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb911-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb911-1" aria-hidden="true" tabindex="-1"></a>pois_ll <span class="ot">&lt;-</span> <span class="cf">function</span>(pars) {</span>
<span id="cb911-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb911-2" aria-hidden="true" tabindex="-1"></a>  a <span class="ot">&lt;-</span> pars[<span class="dv">1</span>]</span>
<span id="cb911-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb911-3" aria-hidden="true" tabindex="-1"></a>  b <span class="ot">&lt;-</span> pars[<span class="dv">2</span>]</span>
<span id="cb911-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb911-4" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> pois_dat<span class="sc">$</span>y</span>
<span id="cb911-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb911-5" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> pois_dat<span class="sc">$</span>x</span>
<span id="cb911-6"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb911-6" aria-hidden="true" tabindex="-1"></a>  linear_predictor <span class="ot">&lt;-</span> a <span class="sc">+</span> b <span class="sc">*</span> x</span>
<span id="cb911-7"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb911-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(y <span class="sc">*</span> (linear_predictor) <span class="sc">-</span> <span class="fu">exp</span>(linear_predictor) <span class="sc">-</span> <span class="fu">lfactorial</span>(y)) </span>
<span id="cb911-8"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb911-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb911-9"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb911-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb911-10"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb911-10" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="st">&#39;pois_ll&#39;</span> <span class="ot">=</span> <span class="fu">pois_ll</span>(<span class="fu">coef</span>(preg)), <span class="st">&#39;logLik&#39;</span> <span class="ot">=</span> <span class="fu">logLik</span>(preg))</span></code></pre></div>
<pre><code>##   pois_ll    logLik 
## -1459.472 -1459.472</code></pre>
<div class="sourceCode" id="cb913"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb913-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb913-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="st">&#39;pois_ll&#39;</span> <span class="ot">=</span> <span class="fu">pois_ll</span>(<span class="fu">c</span>(<span class="fu">coef</span>(preg0), <span class="dv">0</span>)), <span class="st">&#39;logLik&#39;</span> <span class="ot">=</span> <span class="fu">logLik</span>(preg0))</span></code></pre></div>
<pre><code>##   pois_ll    logLik 
## -1723.225 -1723.225</code></pre>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Use <code>pois_ll()</code> to calculate the log-likelihood of <code>pois_dat</code> at the <em>true model parameters</em> <span class="math inline">\(\alpha = 0.2\)</span> and <span class="math inline">\(\beta = 0.6\)</span> that were used to generate <code>x</code> and <code>y</code> in <code>pois_dat</code>. Compare your result to <code>ll_fitted</code> and <code>ll_saturated</code> from above and discuss briefly.</li>
</ol>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb915"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb915-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb915-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="st">&#39;true&#39;</span> <span class="ot">=</span> <span class="fu">pois_ll</span>(<span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.6</span>)), <span class="st">&#39;fitted&#39;</span> <span class="ot">=</span> ll_fitted, <span class="st">&#39;saturated&#39;</span> <span class="ot">=</span> ll_saturated)</span></code></pre></div>
<pre><code>##       true     fitted  saturated 
## -1460.1448 -1459.4717  -889.1677</code></pre>
</div>
<ol start="3" style="list-style-type: decimal">
<li>In fact, <code>ll_fitted</code> and <code>ll_saturated</code> <em>cannot be lower</em> than the value that you computed in the preceding part using <code>pois_ll()</code> evaluated at the true parameter values. Explain why.</li>
<li>As defined above, with a scaling factor of -2, does a higher AIC/BIC indicate a model that we expect to perform <em>better</em> or <em>worse</em> in out-of-sample prediction?</li>
<li>Calculate the AIC and BIC of the null and saturated models from above and compare them to the corresponding AIC and BIC values of <code>preg</code>. Interpret your results.</li>
</ol>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb917"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb917-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb917-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The saturated model has as many parameters as observations</span></span>
<span id="cb917-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb917-2" aria-hidden="true" tabindex="-1"></a><span class="co"># AIC</span></span>
<span id="cb917-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb917-3" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="st">&#39;null&#39;</span> <span class="ot">=</span> <span class="fu">AIC</span>(preg0), <span class="st">&#39;fitted&#39;</span> <span class="ot">=</span> <span class="fu">AIC</span>(preg), </span>
<span id="cb917-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb917-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;saturated&#39;</span> <span class="ot">=</span> <span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> (ll_saturated <span class="sc">-</span> n_obs))</span></code></pre></div>
<pre><code>##      null    fitted saturated 
##  3448.450  2922.943  3778.335</code></pre>
<div class="sourceCode" id="cb919"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb919-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb919-1" aria-hidden="true" tabindex="-1"></a><span class="co"># BIC</span></span>
<span id="cb919-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb919-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="st">&#39;null&#39;</span> <span class="ot">=</span> <span class="fu">BIC</span>(preg0), <span class="st">&#39;fitted&#39;</span> <span class="ot">=</span> <span class="fu">BIC</span>(preg), </span>
<span id="cb919-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb919-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;saturated&#39;</span> <span class="ot">=</span> <span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> (ll_saturated <span class="sc">-</span> <span class="fl">0.5</span> <span class="sc">*</span> n_obs <span class="sc">*</span> <span class="fu">log</span>(n_obs)))</span></code></pre></div>
<pre><code>##      null    fitted saturated 
##  3453.358  2932.759  8686.091</code></pre>
</div>
<ol start="6" style="list-style-type: decimal">
<li>Verify numerically that the deviance of a Poisson regression model equals <span class="math inline">\(2 \sum_{i=1}^n Y_i \log(Y_i / \widehat{Y}_i)\)</span>.</li>
</ol>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb921"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb921-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb921-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb921-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb921-2" aria-hidden="true" tabindex="-1"></a>preg <span class="sc">%&gt;%</span> </span>
<span id="cb921-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb921-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">type.predict =</span> <span class="st">&#39;response&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb921-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb921-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">y_hat =</span> .fitted) <span class="sc">%&gt;%</span></span>
<span id="cb921-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb921-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">D =</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">ifelse</span>(y <span class="sc">&gt;</span> <span class="dv">0</span>, y <span class="sc">*</span> <span class="fu">log</span>(y  <span class="sc">/</span> y_hat), <span class="dv">0</span>)))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 1
##       D
##   &lt;dbl&gt;
## 1 1141.</code></pre>
<div class="sourceCode" id="cb923"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb923-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb923-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(preg)<span class="sc">$</span>deviance</span></code></pre></div>
<pre><code>## [1] 1140.608</code></pre>
</div>
</div>
</div>
<div id="roll-your-own-poisson-mle" class="section level2 hasAnchor" number="10.5">
<h2><span class="header-section-number">10.5</span> Roll Your Own Poisson MLE<a href="poisson-regression-and-maximum-likelihood-estimation.html#roll-your-own-poisson-mle" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>How does <code>glm()</code> calculate the estimated coefficients for Poisson or logistic regression? Unlike OLS, neither of these estimators has an explicit closed-form solution. To get a hint of what's going on under the hood, we can look at the very last line of the <code>summary()</code> output for <code>preg</code></p>
<div class="sourceCode" id="cb925"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb925-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb925-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(preg)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = y ~ x, family = poisson(link = &quot;log&quot;), data = pois_dat)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.9173  -1.0939  -0.1927   0.5520   3.2948  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  0.22936    0.03021   7.592 3.16e-14 ***
## x            0.60079    0.02633  22.818  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1668.1  on 999  degrees of freedom
## Residual deviance: 1140.6  on 998  degrees of freedom
## AIC: 2922.9
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>To estimate this model, <code>glm()</code> uses an iterative procedure called <a href="https://en.wikipedia.org/wiki/Scoring_algorithm">Fisher scoring</a>, a special case of <a href="https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization">Newton's method</a>.<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a> While neither has a closed-form solution, the Poisson and logistic likelihood functions are <em>globally concave</em>. This means that each has a unique, global maximum at the parameter values that make the <a href="https://en.wikipedia.org/wiki/Score_(statistics)">score</a> equal to zero.<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a> This makes both Poisson and logistic regression <em>extremely easy</em> optimization problems. For this reason, practically any numerical optimization routine can be used to run a Poisson or logistic regression, although some will be more efficient than others. In this case the <code>summary()</code> output informs us that five iterations were required before the Fisher scoring algorithm converged to the maximum likelihood estimate.</p>
<p>As a general rule, you should <em>not</em> rely on writing your own code to solve common and well-studied problems like Poisson regression. We have fantastic open-source software libraries written by experts in numerical analysis: use those instead! But there will come a time when you need to solve a problem for which code is <em>not</em> already available. And even when a library is available to do the heavy-lifting for you, it can be dangerous to use a library that you don't really understand. Writing your own implementation for a simple example and checking it against the results from an established library is a fantastic way to get a better understanding of your problem. One of these days you're going to have to maximize a likelihood function that isn't a special case of <code>glm()</code> or any other R package. The purpose of this section is to help you understand how you might go about it. Numerical optimization is a vast subject and we don't have time to do it justice here. For today we will content ourselves with learning the bare minimum that you will need to "roll your own" Poisson regression in R.</p>
<p>To start off we need a simple function example to experiment with. Define the function <span class="math inline">\(h(\cdot)\)</span> as follows
<span class="math display">\[
h(\mathbf{x}) = x_1^2 + x_2^2 + x_1 x_2.
\]</span>
Computing the first and second derivatives of <span class="math inline">\(h(\cdot)\)</span> we obtain
<span class="math display">\[
\frac{\partial h}{\partial \mathbf{x}}  =
\begin{bmatrix}
\displaystyle\frac{\partial h}{\partial x_1} \\
\displaystyle\frac{\partial h}{\partial x_2}
\end{bmatrix} =
\begin{bmatrix}
2 x_1 + x_2 \\
2 x_2 + x_1
\end{bmatrix}, \quad
\frac{\partial^2 h}{\partial \mathbf{x} \partial \mathbf{x}&#39;} =
\begin{bmatrix}
\displaystyle\frac{\partial^2 h}{\partial x_1^2} &amp; \displaystyle\frac{\partial^2 h}{\partial x_1 \partial x_2} \\
\displaystyle\frac{\partial h}{\partial x_1 \partial x_2} &amp; \displaystyle\frac{\partial h}{\partial x_2^2}
\end{bmatrix} =
\begin{bmatrix}
2 &amp; 1 \\
1 &amp; 2
\end{bmatrix}
\]</span>
Because the matrix of second derivatives (the <a href="https://en.wikipedia.org/wiki/Hessian_matrix">Hessian matrix</a>) is positive definite for any value of <span class="math inline">\(\mathbf{x}\)</span>, this function is globally convex. Its unique, global <em>minimum</em> occurs at <span class="math inline">\(x_1 = x_2 = 0\)</span>, as we can see from this contour plot:</p>
<div class="sourceCode" id="cb927"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb927-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-1" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb927-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-2" aria-hidden="true" tabindex="-1"></a>  x1 <span class="ot">&lt;-</span> x[<span class="dv">1</span>]</span>
<span id="cb927-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-3" aria-hidden="true" tabindex="-1"></a>  x2 <span class="ot">&lt;-</span> x[<span class="dv">2</span>]</span>
<span id="cb927-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-4" aria-hidden="true" tabindex="-1"></a>  x1<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> x2<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> x1 <span class="sc">*</span> x2 </span>
<span id="cb927-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb927-6"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb927-7"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-7" aria-hidden="true" tabindex="-1"></a>contour_dat <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">x1 =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="at">length.out =</span> <span class="dv">30</span>),  </span>
<span id="cb927-8"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-8" aria-hidden="true" tabindex="-1"></a>                           <span class="at">x2 =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="at">length.out =</span> <span class="dv">30</span>))</span>
<span id="cb927-9"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-9" aria-hidden="true" tabindex="-1"></a>contour_dat <span class="ot">&lt;-</span> contour_dat <span class="sc">%&gt;%</span> </span>
<span id="cb927-10"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb927-11"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">h_x =</span> <span class="fu">h</span>(<span class="fu">c_across</span>(x1<span class="sc">:</span>x2)))</span>
<span id="cb927-12"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb927-13"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-13" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(contour_dat, <span class="fu">aes</span>(<span class="at">x =</span> x1, <span class="at">y =</span> x2, <span class="at">z =</span> h_x)) <span class="sc">+</span></span>
<span id="cb927-14"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_contour_filled</span>() <span class="sc">+</span></span>
<span id="cb927-15"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">&#39;dashed&#39;</span>) <span class="sc">+</span> </span>
<span id="cb927-16"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb927-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span>  <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">&#39;dashed&#39;</span>)</span></code></pre></div>
<p><img src="erm-book_files/figure-html/unnamed-chunk-451-1.png" width="672" /></p>
<p>It's a bit silly to optimize <span class="math inline">\(h(\cdot)\)</span> given that the solution is obvious, but let's try it anyway! R's general purpose function for numerical optimization is called <code>optim()</code>. Given a vector <code>par</code> of starting values and an objective function <code>fn</code>, <code>optim()</code> uses numerical methods to approximate the <strong>minimum</strong> of <code>fn</code>. If you instead want to <strong>maximize</strong> <code>fn</code> the simplest approach is to apply a different function to <code>optim()</code>, one that returns <code>-1</code> multiplied by <code>fn</code>.</p>
<p>Let's test it out on <code>h()</code> from above using intentionally horrible starting values of <code>c(-100, 100)</code></p>
<div class="sourceCode" id="cb928"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb928-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb928-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">par =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">100</span>, <span class="dv">100</span>), <span class="at">fn =</span> h)</span>
<span id="cb928-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb928-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(results)</span></code></pre></div>
<pre><code>## List of 5
##  $ par        : num [1:2] -0.00107 0.00634
##  $ value      : num 3.45e-05
##  $ counts     : Named int [1:2] 63 NA
##   ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;function&quot; &quot;gradient&quot;
##  $ convergence: int 0
##  $ message    : NULL</code></pre>
<div class="sourceCode" id="cb930"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb930-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb930-1" aria-hidden="true" tabindex="-1"></a>results</span></code></pre></div>
<pre><code>## $par
## [1] -0.001073222  0.006340452
## 
## $value
## [1] 3.454842e-05
## 
## $counts
## function gradient 
##       63       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<p>As we can see, <code>optim()</code> returns a <em>list</em>. The element <code>par</code> contains the parameter values that minimize the objective function, while the element <code>value</code> contains the value of the objective function evaluated at <code>par</code>, and <code>counts</code> tells us how many iterations were needed to reach convergence. The element <code>convergence</code> provides a numeric code that tells us how and why the optimization routine terminated. A value of <code>0</code> means that the algorithm converged. A value of <code>1</code> means that the algorithm did not converge and instead terminated because it reached the maximum number of allowable iterations.</p>
<p>Notice that the solution provided by <code>optim()</code> is good, but <em>not perfect</em>. From our calculus exercise above, we know that the minimum occurs at <span class="math inline">\(x_1 = x_2 = 0\)</span> and <span class="math inline">\(h(\mathbf{0}) = 0\)</span>. Some inaccuracy is inevitable because the algorithm <em>terminates</em> once the change in parameter values between iterations becomes sufficiently small but we might hope for a better approximation when optimizing such a simple function. The number of iterations required to obtain this solution also seems a bit high: 63 compared to a mere <em>handful</em> for the Fisher scoring algorithm used by <code>glm()</code> to estimate <code>preg</code>. Can we do better?</p>
<p>The answer is <strong>yes</strong>. By default, <code>optim()</code> uses the <a href="https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method">Nelder-Mead</a> method, a heuristic optimization approach that doesn't rely on derivatives to update parameter values across iterations. The help file for <code>optim()</code> describes this approach as "slow but robust." Because <span class="math inline">\(h(\cdot)\)</span> is such a well-behaved function (globally convex!) we don't need this robustness. And by eschewing the use of derivative information, we're leaving money on the table. Let's try a slightly different approach. We'll again use <code>optim()</code> but this time we'll set <code>method = BFGS</code> so that it uses the <a href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm">Broyden–Fletcher–Goldfarb–Shanno</a> algorithm rather than Nelder-Mead. When setting <code>method = BFGS</code>, <code>optim()</code> gives us the option of supplying <em>another</em> function called <code>gr</code> that evaluates the gradient of <code>h()</code>. (If we don't supply <code>gr</code> but use BFGS, <code>optim()</code> will approximate the gradient numerically.) This approach gives <em>dramatically better</em> performance:</p>
<div class="sourceCode" id="cb932"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb932-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb932-1" aria-hidden="true" tabindex="-1"></a>h_gradient <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb932-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb932-2" aria-hidden="true" tabindex="-1"></a>  x1 <span class="ot">&lt;-</span> x[<span class="dv">1</span>]</span>
<span id="cb932-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb932-3" aria-hidden="true" tabindex="-1"></a>  x2 <span class="ot">&lt;-</span> x[<span class="dv">2</span>]</span>
<span id="cb932-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb932-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(<span class="dv">2</span> <span class="sc">*</span> x1 <span class="sc">+</span> x2, </span>
<span id="cb932-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb932-5" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span> <span class="sc">*</span> x2 <span class="sc">+</span> x1)</span>
<span id="cb932-6"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb932-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb932-7"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb932-7" aria-hidden="true" tabindex="-1"></a><span class="fu">optim</span>(<span class="at">par =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">100</span>, <span class="dv">100</span>), <span class="at">fn =</span> h, <span class="at">gr =</span> h_gradient, <span class="at">method =</span> <span class="st">&#39;BFGS&#39;</span>)</span></code></pre></div>
<pre><code>## $par
## [1] 0 0
## 
## $value
## [1] 0
## 
## $counts
## function gradient 
##        2        2 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<p>We converge in only two iterations and get the solution exactly correct, up to the precision with which R displays numerical results by default. Please don't interpret this to mean that Nelder-Mead is always a bad idea: it isn't! But for simple problems, like logit or Poisson regression, there are better alternatives.</p>
<div id="exercise-59" class="section level3 hasAnchor" number="10.5.1">
<h3><span class="header-section-number">10.5.1</span> Exercise<a href="poisson-regression-and-maximum-likelihood-estimation.html#exercise-59" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>Make a contour plot of <code>pois_ll()</code> over a grid of values for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> ranging from -1 to 1. Use vertical and horizontal lines to indicate the maximum likelihood estimates from <code>preg</code>.</li>
</ol>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb934"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb934-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb934-1" aria-hidden="true" tabindex="-1"></a>poisson_contour <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">a =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">40</span>),   </span>
<span id="cb934-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb934-2" aria-hidden="true" tabindex="-1"></a>                               <span class="at">b =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">40</span>))</span>
<span id="cb934-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb934-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb934-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb934-4" aria-hidden="true" tabindex="-1"></a>poisson_contour <span class="ot">&lt;-</span> poisson_contour <span class="sc">%&gt;%</span> </span>
<span id="cb934-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb934-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb934-6"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb934-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ll =</span> <span class="fu">pois_ll</span>(<span class="fu">c_across</span>(a<span class="sc">:</span>b)))</span>
<span id="cb934-7"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb934-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb934-8"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb934-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(poisson_contour, <span class="fu">aes</span>(<span class="at">x =</span> a, <span class="at">y =</span> b, <span class="at">z =</span> ll)) <span class="sc">+</span></span>
<span id="cb934-9"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb934-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_contour_filled</span>() <span class="sc">+</span> </span>
<span id="cb934-10"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb934-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">coef</span>(preg)[<span class="dv">1</span>], <span class="at">linetype =</span> <span class="st">&#39;dashed&#39;</span>) <span class="sc">+</span></span>
<span id="cb934-11"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb934-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">coef</span>(preg)[<span class="dv">2</span>], <span class="at">linetype =</span> <span class="st">&#39;dashed&#39;</span>) </span></code></pre></div>
<p><img src="erm-book_files/figure-html/unnamed-chunk-454-1.png" width="672" /></p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Use <code>optim()</code> to maximize <code>pois_ll()</code> with the default method: Nelder Mead. How do your results compare to those from <code>preg</code>?</li>
</ol>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb935"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb935-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb935-1" aria-hidden="true" tabindex="-1"></a>mystart <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">mean</span>(pois_dat<span class="sc">$</span>y), <span class="dv">0</span>)</span>
<span id="cb935-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb935-2" aria-hidden="true" tabindex="-1"></a>neg_pois_ll <span class="ot">&lt;-</span> <span class="cf">function</span>(pars) <span class="sc">-</span><span class="fu">pois_ll</span>(pars)</span>
<span id="cb935-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb935-3" aria-hidden="true" tabindex="-1"></a>results_NM <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">par =</span> mystart, <span class="at">fn =</span> neg_pois_ll)</span>
<span id="cb935-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb935-4" aria-hidden="true" tabindex="-1"></a>results_NM</span></code></pre></div>
<pre><code>## $par
## [1] 0.2290988 0.6008066
## 
## $value
## [1] 1459.472
## 
## $counts
## function gradient 
##       53       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
</div>
<ol start="3" style="list-style-type: decimal">
<li>Repeat the preceding part, but this time use BFGS and supply a function to compute the gradient of <code>pois_ll()</code>. How do the results change?</li>
</ol>
<div class="webex-solution">
<button>
Show Solution
</button>
<div class="sourceCode" id="cb937"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb937-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-1" aria-hidden="true" tabindex="-1"></a>neg_pois_ll_grad <span class="ot">&lt;-</span> <span class="cf">function</span>(pars){</span>
<span id="cb937-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-2" aria-hidden="true" tabindex="-1"></a>  a <span class="ot">&lt;-</span> pars[<span class="dv">1</span>] </span>
<span id="cb937-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-3" aria-hidden="true" tabindex="-1"></a>  b <span class="ot">&lt;-</span> pars[<span class="dv">2</span>]</span>
<span id="cb937-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb937-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-5" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> pois_dat<span class="sc">$</span>y</span>
<span id="cb937-6"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-6" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> pois_dat<span class="sc">$</span>x</span>
<span id="cb937-7"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb937-8"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-8" aria-hidden="true" tabindex="-1"></a>  u <span class="ot">&lt;-</span> y <span class="sc">-</span> <span class="fu">exp</span>(a <span class="sc">+</span> b <span class="sc">*</span> x)</span>
<span id="cb937-9"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-9" aria-hidden="true" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">1</span> <span class="sc">*</span> <span class="fu">c</span>(<span class="fu">sum</span>(u), <span class="fu">sum</span>(x <span class="sc">*</span> u))</span>
<span id="cb937-10"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-10" aria-hidden="true" tabindex="-1"></a>}  </span>
<span id="cb937-11"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-11" aria-hidden="true" tabindex="-1"></a>results_BFGS <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">par =</span> mystart, <span class="at">fn =</span> neg_pois_ll, <span class="at">gr =</span> neg_pois_ll_grad,</span>
<span id="cb937-12"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-12" aria-hidden="true" tabindex="-1"></a>                      <span class="at">method =</span> <span class="st">&#39;BFGS&#39;</span>)</span>
<span id="cb937-13"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb937-13" aria-hidden="true" tabindex="-1"></a>results_BFGS</span></code></pre></div>
<pre><code>## $par
## [1] 0.2293584 0.6007881
## 
## $value
## [1] 1459.472
## 
## $counts
## function gradient 
##       38        9 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
</div>
</div>
</div>
<div id="bonus-material-stirlings-approximation" class="section level2 hasAnchor" number="10.6">
<h2><span class="header-section-number">10.6</span> Bonus Material: Stirling's Approximation<a href="poisson-regression-and-maximum-likelihood-estimation.html#bonus-material-stirlings-approximation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the exercises above, you saw that <span class="math inline">\(171!\)</span> is too large a number for R to represent: it evaluates to <code>Inf</code>. We were nevertheless able to evaluate the Poisson pmf "by hand" by taking logs and then exponentiating the result. To do this, we relied on the function <code>lfactorial()</code> to compute the <em>logarithm</em> of a factorial. But if R can't calculate <span class="math inline">\(171!\)</span>, how is it supposed to calculate the <em>log</em> of this quantity? This section will not explain the precise method that R uses to compute <code>lfactorial()</code>, but it <em>will</em> show you a simple and surprisingly accurate approximation to the logarithm of a factorial that can be very useful in practice.</p>
<p>As we saw above, for large <span class="math inline">\(\mu\)</span> the Poisson<span class="math inline">\((\mu)\)</span> pmf is well-approximated by the Normal<span class="math inline">\((\mu, \mu)\)</span> density:
<span class="math display">\[
\frac{e^{-\mu}\mu^x}{x!} \approx \frac{1}{\sqrt{2\pi \mu}} \exp\left\{ -\frac{1}{2}\left( \frac{x - \mu}{\sqrt{\mu}}\right)^2\right\}
\]</span>
This approximation is particularly accurate for <span class="math inline">\(x\)</span> near the <em>mean</em>. This is convenient, because substituting <span class="math inline">\(\mu\)</span> for <span class="math inline">\(x\)</span> considerably simplifies the right hand side:
<span class="math display">\[
\frac{e^{-\mu}\mu^\mu}{\mu!} \approx \frac{1}{\sqrt{2\pi\mu}}
\]</span>
Re-arranging, we obtain
<span class="math display">\[
\mu! \approx \mu^\mu e^{-\mu} \sqrt{2 \pi \mu}
\]</span>
Taking logs of both sides gives:
<span class="math display">\[
\log(\mu!) \approx \mu \log(\mu) - \mu + \frac{1}{2} \log(2 \pi \mu)
\]</span>
This is called <em>Stirling's Approximation</em>, and it is surprisingly accurate even for relatively small values of <code>x</code>:</p>
<div class="sourceCode" id="cb939"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb939-1"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb939-1" aria-hidden="true" tabindex="-1"></a>stirling_lfactorial <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb939-2"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb939-2" aria-hidden="true" tabindex="-1"></a>  x <span class="sc">*</span> <span class="fu">log</span>(x) <span class="sc">-</span> x <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span> <span class="sc">*</span> pi <span class="sc">*</span> x)</span>
<span id="cb939-3"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb939-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb939-4"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb939-4" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>) <span class="sc">%&gt;%</span></span>
<span id="cb939-5"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb939-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Stirling =</span> <span class="fu">stirling_lfactorial</span>(x),  </span>
<span id="cb939-6"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb939-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">R =</span> <span class="fu">lfactorial</span>(x)) <span class="sc">%&gt;%</span></span>
<span id="cb939-7"><a href="poisson-regression-and-maximum-likelihood-estimation.html#cb939-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">20</span>)</span></code></pre></div>
<pre><code>## # A tibble: 20 × 3
##        x Stirling      R
##    &lt;int&gt;    &lt;dbl&gt;  &lt;dbl&gt;
##  1     1  -0.0811  0    
##  2     2   0.652   0.693
##  3     3   1.76    1.79 
##  4     4   3.16    3.18 
##  5     5   4.77    4.79 
##  6     6   6.57    6.58 
##  7     7   8.51    8.53 
##  8     8  10.6    10.6  
##  9     9  12.8    12.8  
## 10    10  15.1    15.1  
## 11    11  17.5    17.5  
## 12    12  20.0    20.0  
## 13    13  22.5    22.6  
## 14    14  25.2    25.2  
## 15    15  27.9    27.9  
## 16    16  30.7    30.7  
## 17    17  33.5    33.5  
## 18    18  36.4    36.4  
## 19    19  39.3    39.3  
## 20    20  42.3    42.3</code></pre>

</div>
</div>





































<div class="footnotes">
<hr />
<ol start="27">
<li id="fn27"><p>We'd need some strong assumptions for this to really hold, but bear with me: it's at least <em>possible</em>.<a href="poisson-regression-and-maximum-likelihood-estimation.html#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p>For more details on the Poisson regression model, see my
<a href="https://www.economictricks.com/limdep-notes.pdf">lecture notes</a> and <a href="https://www.economictricks.com/videos/">videos</a>.<a href="poisson-regression-and-maximum-likelihood-estimation.html#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p>Some sources call this procedure <a href="https://en.wikipedia.org/wiki/Iteratively_reweighted_least_squares">iteratively reweighted least square</a> because that is, in fact, what it amounts to!<a href="poisson-regression-and-maximum-likelihood-estimation.html#fnref29" class="footnote-back">↩︎</a></p></li>
<li id="fn30"><p>There are two key exceptions to this claim. The first concerns perfect multi-collinearity: if any of the regressors in the linear predictor <span class="math inline">\(X&#39;\beta\)</span> is exactly equal to a linear combination of the others, the MLE fails to be unique. This is easy to fix in practice since we can simply drop the offending regressor. The second is a phenomenon called <a href="https://stats.stackexchange.com/questions/239928/is-there-any-intuitive-explanation-of-why-logistic-regression-will-not-work-for">perfect separation</a> that can occur in logistic regression when it's <em>too easy</em> to predict <span class="math inline">\(Y\)</span> using <span class="math inline">\(X\)</span>.<a href="poisson-regression-and-maximum-likelihood-estimation.html#fnref30" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  if (t = document.getElementById("webex-total_correct")) {
    var correct = document.getElementsByClassName("webex-correct").length;
    var solvemes = document.getElementsByClassName("webex-solveme").length;
    var radiogroups = document.getElementsByClassName("webex-radiogroup").length;
    var selects = document.getElementsByClassName("webex-select").length;
    
    t.innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");
  
  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");
  
  var cl = this.classList
  
  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }
  
  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;
  
  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }
  
  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }
  
  update_total_correct();
}

window.onload = function() {
  console.log("onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;
  }
  
  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }
  
  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
  }

  update_total_correct();
}

</script>
            </section>

          </div>
        </div>
      </div>
<a href="data-rodeo.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
