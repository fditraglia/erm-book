[["index.html", "Empirical Research Methods Preface About This Book Pre-requisites Why not Stata? Why not Matlab, Julia, or Python?", " Empirical Research Methods Francis J. DiTraglia 2022-02-20 Preface About This Book Supervising undergraduate, masters-level, and doctoral research students has shown me just how many of the skills that I take for granted in my day-to-day work were never taught in a course, but acquired through years of painful trial-and-error. You've probably heard that \"the only way to learn how to do research is by doing research.\" Indeed: classroom exercises are always somewhat artificial, and there is no substitute for getting your hands dirty with a problem that really matters to you. But trial-and-error is a slow and clumsy way to gain proficiency, and throwing students in at the deep end is neither a recipe for academic success nor for mental well-being. The goal of this book is to put some structure around the process through which students learn to do empirical work in economics, building a strong foundation for later self-directed reading and research. The book is divided into twenty-odd short chapters called lessons, each designed to take between one and two hours to complete. Broadly speaking, the material is a mix of applied econometrics, data science, and research skills. In keeping with the Swiss Army Knife logo, the idea is to teach you lots of little things that will come in handy later. While the topics covered below are something of a miscellany, there are strong connections between the lessons. For best results, complete them in order. A key theme that runs throughout the lessons is the importance of reproducible research using open-source tools. Reproducible research is about creating a clean and fully-documented path from raw data to final results, making errors less likely to occur and easier to find when they do. It also allows other researchers, or our future selves, to build on past work, expanding the sum total of knowledge. Of course I can only replicate your research if I can run your code, and this is why open-source software is so important. Fortunately there are many fantastic open-source programming languages to choose from. This book uses R, the lingua franca of statistics and an increasingly popular choice among economists. Pre-requisites This book does not assume advanced knowledge of programming, mathematics, or econometrics, but it does have some pre-requisites. My target audience is first-year graduate students and final-year undergraduates in economics. At Oxford, I use this book to teach a first-year master's level course on Empirical Research Methods that comes after students have completed 16 weeks of basic statistics and econometrics. I assume that you've taken an econometrics course that uses matrix notation and that you have basic familiarity with R programming. If you need to brush up on econometrics, I recommend Marno Verbeek's Guide to Modern Econometrics. I've linked to the third edition because it is particularly inexpensive to buy a used copy, but any edition will do. At a more advanced level, Bruce Hansen's two volume series Econometrics is both excellent and free to download online. If you haven't used R before or feel the need for a bit of review, I suggest reading Hands-On Programming with R. It's free, short, and will get you up to speed quickly. Why not Stata? Given that much of the material discussed below falls under the broad category of \"applied microeconometrics\" you may wonder why I chose R rather than Stata. Indeed, Stata is easy-to-use, and makes it relatively painless to implement \"textbook\" microeconometric methods.1 So why don't I like Stata? Before beginning my polemic I should be absolutely clear that Stata users are not bad people: hate the sin, love the sinner. Here begins the sermon. First, Stata is expensive. The price for a Business single-user Stata license is $765 per year.2 If you want support for multicore computing, the price is even higher: an 8-core version of Stata costs $1,395 annually. There is no discount for Government or nonprofits, but as an Oxford faculty member, I can obtain an 8-core version of Stata for the low price of $595 per year, or around 9% of my annual research allowance. In contrast, the tools that we will learn in this book, mainly R and C++, are completely free. This is particularly important in the modern world of high-performance cluster computing. If you're considering running your code on a multicore machine on Amazon, Google, or Microsoft cloud servers, you don't want to pay a software license fee for every core that you use. Second, Stata is almost comically behind the times. Let's see what's new in Stata version 16, released in February 2020.3 At the top of the list is the LASSO, a wildly popular technique for high-dimensional regression. Rob Tibshirani developed this method in a seminal paper from 1996, so it only took 24 years for it to be incorporated into Stata.4 Fortunately, Tibshirani and his co-authors made it easy for Stata, by releasing open-source software to implement the LASSO and related methods in R over a decade ago.5 Next on the list of new Stata features is linear programming, a technique that came to prominence in the late 1940s.6 Stata 16 also has the ability to call \"any Python package\"--something you can do for free in R using reticulate or in Python itself for that matter--and \"truly reproducible reporting.\" Reproducible reporting is incredibly valuable, and it's something that we'll cover in detail below. It's also been available in R, completely free of charge, since at least 2002.7 I suppose we shouldn't expect too much of a statistical computing package that only added support for matrix programming in 2005, a full 20 years after Stata version 1.0.8 Third, Stata is a black box. Because the underlying source code is kept secret, there's no way for a Stata user to know for certain what's happening under the hood. A few years ago I tried to determine precisely what instrument set Stata was using in its implementation of a well-known dynamic panel estimator. The documentation was vague, so I resorted to reverse-engineering the Stata results by trial-and-error in R. I never did get the results to match perfectly. In contrast, if you're not sure what a particular R function or package is doing, you can simply read the source code and find out. Fourth, and most importantly, Stata makes it hard to share with others. If I don't own a copy of Stata, I can't replicate your work. Even if I do own a copy of Stata, I still may not be able to so do: Stata's proprietary binary data formats are updated fairly regularly and do not maintain backwards compatibility. Datafiles created in Stata version 16, for example, cannot be opened in Stata 13. Indeed, depending on the number of variables included in your dataset, Stata 16 files cannot necessarily be opened even in Stata 15. Fortunately, as we'll see below, intrepid open-source programmers have developed free software to unlock data from Stata's proprietary and ever-changing binary formats. Why not Matlab, Julia, or Python? Unlike Stata, Matlab is a bona fide programming language and a fairly capable one at that. Nevertheless, my other critiques of Stata from above still apply: Matlab is extremely expensive, and it's not open source. In contrast, I have nothing bad to say about Python and Julia: they're great languages and you should consider learning one or both of them! A good resources aimed at economists is the quantecon.org: https://python.quantecon.org/ and https://julia.quantecon.org/. In the end I decided to choose one language and R struck me as the best choice for the moment. In five or ten years time, I could easily imagine re-writing this book in Julia, but as of this writing R has the advantage of maturity and a large, and generally extremely supportive community of users. Even if you ultimately decide that R isn't for you, fear not! After learning the material in this book, you'll find it fairly easy to transition to Python or Julia, should you so choose. Now let's get started! Arguably, Stata is too easy to learn precisely because of the incentives faced by a software developer with monopoly power: see Hal Varian's paper: Economic Incentives in Software Design.↩︎ These figures were accurate as of March 2021. For the latest prices, see https://www.stata.com/order/dl/.↩︎ https://www.stata.com/new-in-stata/↩︎ Tibshirani (1996) - Regression Shrinkage and Selection via the Lasso↩︎ Friedman et al (2010) - Regularization Paths for Generalized Linear Models via Coordinate Descent↩︎ For a history of linear programming, see Dantzig (1983). To be completely fair, the linear programming algorithm implemented in Stata 16 was only developed in 1992, a lag of merely 28 years.↩︎ Reproducible reporting in R started with sweave. These days we have a fantastic successor package called knitr, which I cover below.↩︎ The \"Mata\" programming language was added in Stata 9: https://www.stata.com/stata9/. For a timeline of Stata versions, see https://www.stata.com/support/faqs/resources/history-of-stata/.↩︎ "],["how-to-outsmart-a-nobel-laureate.html", "Lesson 1 How to Outsmart a Nobel Laureate 1.1 The Hot Hand 1.2 Update from here down! 1.3 Hidden solutions and hints", " Lesson 1 How to Outsmart a Nobel Laureate 1.1 The Hot Hand If you've read 2002 Nobel Laureate Daniel Kahneman's best-selling book Thinking Fast and Slow, you may remember this passage about the hot hand illusion, a supposed illustration of the human tendency to see patterns in random noise: Amos [Tversky] and his students Tom Gilovich and Robert Vallone caused a stir with their study of misperceptions of randomness in basketball. The \"fact\" that players occasionally acquire a hot hand is generally accepted by players, coaches, and fans. The inference is irresistible: a player sinks three or four baskets in a row and you cannot help forming the causal judgment that this player is now hot, with a temporarily increased propensity to score. Players on both teams adapt to this judgment—teammates are more likely to pass to the hot scorer and the defense is more likely to doubleteam. Analysis of thousands of sequences of shots led to a disappointing conclusion: there is no such thing as a hot hand in professional basketball, either in shooting from the field or scoring from the foul line. Of course, some players are more accurate than others, but the sequence of successes and missed shots satisfies all tests of randomness. The hot hand is entirely in the eye of the beholders, who are consistently too quick to perceive order and causality in randomness. The hot hand is a massive and widespread cognitive illusion. The research that Kahneman mentions was published in a famous paper by Gilovich, Vallone &amp; Tversky (1985), and later summarized for a general audience in Gilovich &amp; Tversky (1989). The abstract of the original paper says it all: Basketball players and fans alike tend to believe that a player's chance of hitting a shot are greater following a hit than following a miss on the previous shot. However, detailed analyses of the shooting records of the Philadelphia 76ers provided no evidence for a positive correlation between the outcomes of successive shots. The same conclusions emerged from free-throw records of the Boston Celtics, and from a controlled shooting experiment with the men and women of Cornell's varsity teams. The outcomes of previous shots influenced Cornell players' predictions but not their performance. The belief in the hot hand and the \"detection\" of streaks in random sequences is attributed to a general misconception of chance according to which even short random sequences are thought to be highly representative of their generating process. Between 1985 and 2011, when Kahneman's book was published, this result was replicated numerous times under a variety of different conditions, making it one of the better-documented biases in human decision-making. But it turns out that the hot-hand illusion is itself an illusion. In a recent issue of Econometrica, Miller &amp; Sanjurjo (2018) point out a subtle but consequential error in the statistical tests used in the hot hand literature. It turns out that these tests were biased against detecting evidence of a hot hand, even if it did in fact exist. Correcting this mistake and re-analyzing Gilovich, Vallone and Tversky's original dataset \"reveals significant evidence of streak shooting, with large effect sizes.\" The hot hand is real. There are some helpful lessons that we can draw from this episode. First, we all make mistakes--even Nobel Laureates! Second, successful replications tell us less than we might hope: they could easily reproduce the bias of the original study. But in my view, the real lesson of the hot hand affair is much simpler: you should always run a simulation study. The probabilistic error that led so many researchers to draw the wrong conclusion about the hot hand is really quite subtle.9 But at the same time, anyone who knows basic programming could have detected the mistake in five minutes if only they had bothered to look. In economics and statistics, simulation is a superpower. It helps us to understand our models, check for mistakes, and make unexpected connections, some of which may even lead to new theoretical results. If you'll pardon my continuation of the Swiss Army Knife metaphor, simulation is the knife: arguably the most useful tool in your toolbox. In this lesson, we'll cover some basic tools for carrying out a simulation experiment in R and use them to shed some light on the illusion of the hot hand illusion. 1.2 Update from here down! Should I introduce knitr and Rmarkdown in this lesson or the next one? Some basic simulation commands in R: sample(), rbinom(), rnorm(), etc. Read the help files. Write a function draw_sim_data() that makes 100 Bernoulli(1/2) draws. Optional arguments p and n? This simulates data when there is no hot hand set.seed() what does it do? Think about how to calculate the estimator: fraction of times that three ones are followed by another one compared to another zero. Suppose you had a function is_after_3_ones() that took a vector of 0 and 1 and returned, for each element, whether it is after three ones. How would you use it? Write this function. Put everything together with replicate() to do a simple sim for \\(p=1/2\\) and \\(n = 100\\). How about trying different values of \\(n\\) and \\(p\\)? Need to keep results organized: apply() family of functions (or maybe the tidy equivalents?) Try doing it in parallel with mclapply(). First explain the basic idea of parallel and why this is \"embarrassingly parallel.\" Show them how to time the code, illustrate with sys.sleep(). For the students who finish very quickly, have some extensions: a markov chain DGP, and is_after_k_ones() dgp &lt;- function(n = 100, p = 0.5) { rbinom(n, 1, p) } # Maybe have a challenge to write the version for after k ones, but start by # asking them to do the one for after 3 ones is_after_k_ones &lt;- function(x, k) { out &lt;- rep(NA) for(i in (k+1):length(x)) { out[i] &lt;- sum(x[(i - k):(i - 1)]) == k } return(out) } get_est &lt;- function(x) { #ones &lt;- which(x == 1) #mean(x[ones + 1], na.rm = TRUE) mean(x[is_after_k_ones(x, 3)], na.rm = TRUE) } n_reps &lt;- 1e5 set.seed(1234) sim_results &lt;- replicate(n_reps, get_est(dgp())) library(ggplot2) qplot(sim_results) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 30 rows containing non-finite values (stat_bin). mean(sim_results, na.rm = TRUE) ## [1] 0.4602045 #ones &lt;- which(x == 1) #x[which(x == 1) + 1] #runs &lt;- rle(x) #foo &lt;- rle(x) #str(foo) #x #foo$lengths #foo$values 1.3 Hidden solutions and hints You can fence off a solution area that will be hidden behind a button using hide() before the solution and unhide() after, each as inline R code. Pass the text you want to appear on the button to the hide() function. If the solution is an RMarkdown code chunk, instead of using hide() and unhide(), simply set the webex.hide chunk option to TRUE, or set it to the string you wish to display on the button. 1.3.1 Example problem Recreate the scatterplot below, using the built-in cars dataset. I need a hint See the documentation for plot() (?plot) Click here to see the solution plot(cars$speed, cars$dist) See Miller &amp; Sanjurjo (2019) for a more accessible explanation that connects to several related probability puzzles.↩︎ "],["using-webexercises.html", "Lesson 2 Using webexercises 2.1 Tally the number of correct answers: total_correct() 2.2 Create a TRUE/FALSE question: torf() 2.3 Create fill-in-the-blank Questions: fitb() 2.4 Create a multiple choice question: mcq(), mcqlong() 2.5 Hide Solutions / Create Hints", " Lesson 2 Using webexercises Let's take a look at some of the tools that webexercises provides us. It can be used to tally up the number of correct answers: total_correct() create TRUE/FALSE questions: torf() create fill-in-the-blank questions: fitb() create multiple choice questions: mcq() or longmcq() hide solutions / create hints: hide(), unhide(), or webex.hide = TRUE We'll now examine each of these possibilities in detail. 2.1 Tally the number of correct answers: total_correct() Suppose that you want to keep track of how many questions a user has answered correctly so far. You can do this with the total_correct() function. The elem and args arguments control formatting: elem is used to set header styles, say you wanted h3 instead of h2, and args feeds in raw CSS if you want to make manual tweaks: It doesn't matter where you put total_correct() in your document: it will still work as expected. In this document, for example, it appears near the top. Nevertheless, as you work down to the bottom and answer more questions, the tally will update dynamically. 2.2 Create a TRUE/FALSE question: torf() Supply the correct answer as the first argument to torf(). This should either be TRUE or FALSE, e.g. True or False: \\(\\pi\\) is a rational number. TRUEFALSE 2.3 Create fill-in-the-blank Questions: fitb() As with torf(), supply the correct answer as the first argument of fitb(). The difference is that fitb() allows you to supply something other than TRUE or FALSE as the correct answer, and displays a text field rather than a drop-down menu: \\(8 \\times 9 =\\) This correct answer doesn't have to be hard-coded: you can do calculations in place or supply the name of an R object created elsewhere in your RMarkdown document. This allows you to create a dynamic question and answer. Here's an example in which the question is randomly generated when you knit this document: The square root of 36 is: If the correct answer is E, but a user enters e, this will be marked as incorrect: fitb() is case sensitive. To turn this off, set ignore_case = TRUE. What is the letter after D? By default fitb() ignores whitespace. For example, rnorm ( 3 ) is counted as a correct answer to the following: Write R code to make three independent standard normal draws. If you want fitb() to treat whitespace as meaningful, set ignore_ws = TRUE. Some fill-in-the-blank questions have more than one correct answer. To create such a question, simply supply a vector as the first argument to fitb(): Type a vowel: Want to do something more complicated? No problem! You can supply regular expressions as a solution to fitb() as follows: Type any 3 letters: Here's an example with multiple correct answers to a coding question: How do you load the tidyverse package? I'm not clear on what the width argument does. Look it up! 2.4 Create a multiple choice question: mcq(), mcqlong() Use mcq() to create a \"short\" multiple choice question. The first argument is a vector of answers in which the correct answer is given the name answer and all other elements are un-named, e.g. c('Harris', 'Trump', answer = 'Biden', 'Clinton') in the following: Who was elected president of the United States in November 2020? HarrisTrumpBidenClinton To create a multiple choice question with radio buttons rather than a dropdown menu, use mcqlong(). This tends to result in nicer formatting than a drop-down if the answers to your question are \"long,\" hence the name of the function. When your answers are long, inline R code can be hard to read. To avoid this problem, you can set up your multiple choice answers in a vector within an R chunk with echo=FALSE and then supply that vector as the first argument to longmcq() in an inline R chunk. For example: Which of these statements about p-values is correct? A p-value is the probability that the null hypothesis is true A p-value is the probability of observing a test statistic at least as extreme as the one we actually observed, assuming that the null hypothesis is true. The p-value is the probability of making a mistake when testing a hypothesis. What is true about a 95% confidence interval for the population mean \\(\\mu\\)? Approximately 95% of the values in our dataset will fall within the confidence interval. If we repeatedly draw a sample of the same size from the same population, and construct an interval in this way for each sample, then approximately 95% of the intervals will contain \\(\\mu\\). The probability that \\(\\mu\\) lies in our confidence interval equals 0.95. 2.5 Hide Solutions / Create Hints This is the main piece of functionality that I was hoping to use for my Core ERM course: hiding hints and solutions to exercises and providing buttons that students can click to reveal them. There are two ways to do this: inline, and using R chunks. For inline hints and solutions, put hide() before and unhide() after the hint or solution. Each of these should be inserted as inline R code. Provide a text string as an argument to hide() to control the text displayed on the button. Here's an example: 2.5.1 Example 1: Inline Hint and Solution Make a histogram of 100 independent standard normal draws. Show Hint Look at the R help functions for rnorm() and hist(). Show Solution hist(rnorm(100)) The hide/unhide patter is most useful for hints, where you don't actually want to run any code, and only want to display a sentence or two. For solutions, whether or not you want to run them, it's you'll probably want to use an R chunk. To do this, set the webex.hide option to TRUE. Alternatively you can set webex.hide = 'Your Text Here' to control the text that appears on the button. For a solution that doesn't evaluate, set eval = FALSE. 2.5.2 Example 2: Chunk solution that doesn't execute Show Solution x &lt;- rnorm(100) hist(x) 2.5.3 Example 3: Chunk solution that evaluates Show Solution x &lt;- rnorm(100) hist(x) Sometimes you may want to start by both explaining the exercise and showing the desired output, while hiding the code used to generate it. To avoid re-typing code, create a named chunk with the chunk option echo = FALSE. This chunk will display the output only, not the code used to generate it. Then create an empty chunk below it with the same name but set eval = FALSE and webex.hide=TRUE or webex.hide='Your Text Here'. For this second chunk don't set echo = FALSE. 2.5.4 Example 4: Show the output, hide the code The mtcars dataset contains the following variables: head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 Write code to generate the following plot using this dataset: Show Solution plot(mpg ~ disp, data = mtcars, main = &quot;Fuel Efficiency (mpg) versus Engine Displacement (cc)&quot;) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
