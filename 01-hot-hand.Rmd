# How to Outsmart a Nobel Laureate 

## The Hot Hand

If you've read 2002 Nobel Laureate Daniel Kahneman's best-selling book [*Thinking Fast and Slow*](https://www.google.co.uk/books/edition/Thinking_Fast_and_Slow/AV9x8XakdV0C?hl=en&gbpv=1&dq=thinking+fast+and+slow&printsec=frontcover), you may remember this passage about the *hot hand illusion*, a supposed illustration of the human tendency to see patterns in random noise:

> Amos [Tversky] and his students Tom Gilovich and Robert Vallone caused a stir with their study of misperceptions of randomness in basketball. The "fact" that players occasionally acquire a hot hand is generally accepted by players, coaches, and fans. The inference is irresistible: a player sinks three or four baskets in a row and you cannot help forming the causal judgment that this player is now hot, with a temporarily increased propensity to score. Players on both teams adapt to this judgmentâ€”teammates are more likely to pass to the hot scorer and the defense is more likely to doubleteam. Analysis of thousands of sequences of shots led to a disappointing conclusion: there is no such thing as a hot hand in professional basketball, either in shooting from the field or scoring from the foul line. Of course, some players are more accurate than others, but the sequence of successes and missed shots satisfies all tests of randomness. The hot hand is entirely in the eye of the beholders, who are consistently too quick to perceive order and causality in randomness. The hot hand is a massive and widespread cognitive illusion.

The research that Kahneman mentions was published in a famous paper by [Gilovich, Vallone & Tversky (1985)](https://labs.la.utexas.edu/gilden/files/2016/04/Gilo.Vallone.Tversky.pdf), and later summarized for a general audience in [Gilovich & Tversky (1989)](http://www.medicine.mcgill.ca/epidemiology/hanley/c323/hothand.pdf). The abstract of the original paper says it all:

> Basketball players and fans alike tend to believe that a player's chance of hitting a shot are greater following a hit than following a miss on the previous shot. However, detailed analyses of the shooting records of the Philadelphia 76ers provided no evidence for a positive correlation between the outcomes of successive shots. The same conclusions emerged from free-throw records of the Boston Celtics, and from a controlled shooting experiment with the men and women of Cornell's varsity teams. The outcomes of previous shots influenced Cornell players' predictions but not their performance. The belief in the hot hand and the "detection" of streaks in random sequences is attributed to a general misconception of chance according to which even short random sequences are thought to be highly representative of their generating process.

Between 1985 and 2011, when Kahneman's book was published, this result was replicated numerous times under a variety of different conditions, making it one of the better-documented biases in human decision-making. But it turns out that the hot-hand illusion is *itself* an illusion.  

In a recent issue of *Econometrica*, [Miller \& Sanjurjo (2018)](https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA14943) point out a subtle but consequential error in the statistical tests used in the hot hand literature. It turns out that these tests were biased *against* detecting evidence of a hot hand, even if it did in fact exist. Correcting this mistake and re-analyzing Gilovich, Vallone and Tversky's original dataset "reveals significant evidence of streak shooting, with large effect sizes." The hot hand is real, and the literature has now shifted to trying to estimate the *size* of the effect.^[See for example [this write-up](https://www.nber.org/digest-202202/exploring-hot-hand-basketball) of [Lantis & Nessen (2021)](https://www.nber.org/papers/w29468) in the [February 2022 NBER digest](https://www.nber.org/digest-2022-02).]

There are some helpful lessons that we can draw from this episode. First, we all make mistakes--even Nobel Laureates! Second, successful replications tell us less than we might hope: they could easily *reproduce* the bias of the original study. But in my view, the real lesson of the hot hand affair is much simpler: **you should always run a simulation study.** 

The probabilistic error that led so many researchers to draw the wrong conclusion about the hot hand is really quite subtle.^[See [Miller \& Sanjurjo (2019)](https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.33.3.144) for a more accessible explanation that connects to several related probability puzzles.] But at the same time, anyone who knows basic programming could have detected the mistake in five minutes if only they had bothered to look. In economics and statistics, simulation is a *superpower*. It helps us to understand our models, check for mistakes, and make unexpected connections, some of which may even lead to new theoretical results. If you'll pardon my continuation of the Swiss Army Knife metaphor, simulation is the knife: arguably the most useful tool in your toolbox. In this lesson, we'll cover some basic tools for carrying out a simulation experiment in R and use them to shed some light on the illusion of the hot hand illusion.

## Drawing Random Data in R
### `sample()`
R has many helpful built-in functions for making simulated random draws. The simplest is `sample()`, which makes `size` random draws without replacement from a vector `x`. To test this out, I'll create a very simple vector
```{r}
my_vector <- c('there', 'is', 'no', 'largest', 'integer')
```
The following line of code makes two draws *without replacement*
```{r}
sample(x = my_vector, size = 2) # without replacement
```
If I run the same line of code again, I may not get the same result: it's random!^[Technically, "random" draws made on a computer are only [pseudorandom](https://en.wikipedia.org/wiki/Pseudorandomness).]
```{r}
sample(x = my_vector, size = 2) # without replacement
```

To draw *with replacement*, set `replace = TRUE`
```{r}
sample(x = my_vector, size = 7, replace = TRUE) # with replacement
```
The argument names `x` and `size` are optional.
```{r}
sample(my_vector, 7, replace = TRUE)
```


### Probability Distributions in R 

As a programming language targeted at statistical applications, R supplies built-in functions for all of the most common probability distributions.^[For less common distributions, see [CRAN Task View: Probability Distributions](https://cran.r-project.org/web/views/Distributions.html)]
These functions follow a consistent naming convention. They being with either `d`, `p`, `q`, or `r` and are followed by an abbreviated name for a particular probability distribution. The prefix `d` denotes a *density* function (or mass function for a discrete distribution); `p` denotes a *cumulative distribution function* (CDF), `q` denotes a *quantile* function, and `r` denotes a function for making *random draws* from a particular distribution. For example: `dunif()` gives the probability density function of a uniform random variable, `pnorm()` gives the CDF of a normal random variable, `qchisq()` gives the quantile function of a Chi-squared, and `rbinom` allows us to make random draws from a Binomial distribution. The following table gives a full list of the relevant commands.

| R commands | Distribution |
|:-----------|:--------------|
| `d/p/q/rbeta` | [Beta](https://en.wikipedia.org/wiki/Beta_distribution) |
| `d/p/q/rbinom` | [Binomial](https://en.wikipedia.org/wiki/Binomial_distribution) |
| `d/p/q/rcauchy` | [Cauchy](https://en.wikipedia.org/wiki/Cauchy_distribution) | 
| `d/p/q/rchisq` | [Chi-Squared](https://en.wikipedia.org/wiki/Chi-squared_distribution) |
| `d/p/q/rexp` | [Exponential](https://en.wikipedia.org/wiki/Exponential_distribution) |
| `d/p/q/rf` | [F](https://en.wikipedia.org/wiki/F-distribution) |
| `d/p/q/rgamma` | [Gamma](https://en.wikipedia.org/wiki/Gamma_distribution) |
| `d/p/q/rgeom` | [Geometric](https://en.wikipedia.org/wiki/Geometric_distribution) |
| `d/q/p/rhyper` | [Hypergeometric](https://en.wikipedia.org/wiki/Geometric_distribution) |
| `d/p/q/rlogis` | [Logistic](https://en.wikipedia.org/wiki/Logistic_distribution) |
| `d/p/q/rlnorm` | [Log Normal](https://en.wikipedia.org/wiki/Lognormal_distribution) |
| `d/p/q/rnbinom` | [Negative Binomial](https://en.wikipedia.org/wiki/Negative_binomial_distribution) |
| `d/p/q/rnorm` | [Normal](https://en.wikipedia.org/wiki/Normal_distribution) |
| `d/p/q/rpois` | [Poisson](https://en.wikipedia.org/wiki/Poisson_distribution) |
| `d/p/q/rt` | [Student's t](https://en.wikipedia.org/wiki/Student%27s_t-distribution) |
| `d/p/q/runif` | [Uniform](https://en.wikipedia.org/wiki/Continuous_uniform_distribution) |
| `d/p/q/rweibull` | [Weibull](https://en.wikipedia.org/wiki/Weibull_distribution) |

There's a single help file for all of the `d/p/q/r` functions for a particular distribution. For example, if you enter `?dbeta` and the console you'll be shown the help files for `dbeta()`, `pbeta()`, `qbeta()`, and `rbeta()`.

For the purposes of this chapter we'll need a bit of familiarity with `rbinom()`, the function for drawing from a [Binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution). Recall that a Binomial$(m,p)$ random variable equals the number of heads in $m$ independent tosses of a coin with $\mathbb{P}(\text{Heads})=p$. More formally, it equals the number of *successes* in $m$ independent Bernoulli *trials*, each with probability of success $p$.
The function `rbinom()` takes three arguments: `size` is the number of trials, `prob` is the probability of success on, and `n` is the desired number of Binomial trials. For example, we can make a single draw from a Binomial$(10, 1/2)$ distribution as follows
```{r}
rbinom(n = 1, size = 10, prob = 0.5)
```


### `set.seed()`

A key theme of this book is the importance of *reproducible research*. 

### Exercises
1. Run `sample(x = my_vector, size = 10)`. What happens and why?
`r hide("Show Solution")`
R will throw an error. You can't make ten draws *without replacement* from a set of five objects:
```{r, error=TRUE}
sample(x = my_vector, size = 10)
```
`r unhide()`
2. Write a line of code that makes five draws without replacement from the set of numbers $\{1, 2, 3, ..., 100\}$.
```{r webex.hide="Show Solution"}
sample(1:100, 5)
```
3. Create a vector of thirty elements called `urn` that represents an urn containing ten blue balls and twenty red balls. Draw five balls with replacement from `urn` and store the draws in a vector called `draws`. Then write a line of code to count up the number of blue balls in `draws`.
`r hide("Show Hint")`
Use `rep()` and `c()` to construct `urn`. Use `==` and `sum()` to count up the number of blue balls in `draws`. See the relevant help files for details, e.g. `?rep`.
`r unhide()`
```{r webex.hide="Show Solution"}
urn <- c(rep('blue', 10), rep('red', 20))
draws <- sample(urn, 5, replace = TRUE)
draws
sum(draws == 'blue')
```

## Update from here down!

**Should I introduce `knitr` and `Rmarkdown` in this lesson or the next one?**

1. Some basic simulation commands in R: `sample()`, `rbinom()`, `rnorm()`, etc. Read the help files.
2. Write a function `draw_sim_data()` that makes 100 Bernoulli(1/2) draws. Optional arguments `p` and `n`? This simulates data when there is *no hot hand*
3. `set.seed()` what does it do?
4. Think about how to calculate the estimator: fraction of times that three ones are followed by another one compared to another zero. Suppose you had a function `is_after_3_ones()` that took a vector of 0 and 1 and returned, for each element, whether it is after three ones. How would you use it? Write this function.
5. Put everything together with `replicate()` to do a simple sim for $p=1/2$ and $n = 100$.
6. How about trying different values of $n$ and $p$? Need to keep results organized: `apply()` family of functions (or maybe the tidy equivalents?)
7. Try doing it in parallel with `mclapply()`. First explain the basic idea of parallel and why this is "embarrassingly parallel." Show them how to time the code, illustrate with `sys.sleep()`. 
8. For the students who finish very quickly, have some extensions: a markov chain DGP, and `is_after_k_ones()`

```{r}
dgp <- function(n = 100, p = 0.5) {
  rbinom(n, 1, p)
}

# Maybe have a challenge to write the version for after k ones, but start by
# asking them to do the one for after 3 ones
is_after_k_ones <- function(x, k) {
  out <- rep(NA)
  for(i in (k+1):length(x)) {
    out[i] <- sum(x[(i - k):(i - 1)]) == k
  }
  return(out)
}

get_est <- function(x) {
  #ones <- which(x == 1)
  #mean(x[ones + 1], na.rm = TRUE)
  mean(x[is_after_k_ones(x, 3)], na.rm = TRUE)
}

n_reps <- 1000
set.seed(1234)
sim_results <- replicate(n_reps, get_est(dgp()))
library(ggplot2)
qplot(sim_results)
mean(sim_results, na.rm = TRUE)

#ones <- which(x == 1)
#x[which(x == 1) + 1]
#runs <- rle(x)
#foo <- rle(x)
#str(foo)
#x
#foo$lengths
#foo$values
```


## Hidden solutions and hints

You can fence off a solution area that will be hidden behind a button using `hide()` before the solution and `unhide()` after, each as inline R code.  Pass the text you want to appear on the button to the `hide()` function.

If the solution is an RMarkdown code chunk, instead of using `hide()` and `unhide()`, simply set the `webex.hide` chunk option to TRUE, or set it to the string you wish to display on the button.

### Example problem

**Recreate the scatterplot below, using the built-in `cars` dataset.**

```{r echo = FALSE}
with(cars, plot(speed, dist))
```


`r hide("I need a hint")`

See the documentation for `plot()` (`?plot`)

`r unhide()`


<!-- note: you could also just set webex.hide to TRUE -->

```{r eval = FALSE, webex.hide="Click here to see the solution"}
plot(cars$speed, cars$dist)
```

<!-- TO CHANGE WIDGET COLOURS:
  move command below out of this HTML comment area
  and then re-compile;
  unfilled becomes yellow, correct becomes pink 
     
`r style_widgets("#FFFF00", "#FF3399")`
-->
